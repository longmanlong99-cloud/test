# -*- coding: utf-8 -*-
"""
ç¾è‚¡å´©ç›˜é¢„è­¦ç³»ç»Ÿ - 21å› å­ V10.057 (Robust Report Edition)
ã€ç´§æ€¥ä¿®å¤ã€‘
1. ä¿®å¤ UnboundLocalError: ç»™ adv, dec ç­‰å…³é”®å˜é‡å¢åŠ äº†åˆå§‹é»˜è®¤å€¼(0)ã€‚
   å³ä½¿ Firecrawl æŠ“å–å¤±è´¥ï¼Œç¨‹åºä¹Ÿä¼šç»§ç»­è¿è¡Œï¼Œç»ä¸ä¼šåŠè·¯å´©æºƒã€‚
2. å†…å®¹å…¨å¼€: æ¢å¤äº†æ‰€æœ‰ Deep Analysis çš„æ–‡å­—è¾“å‡ºï¼Œä¸åšä»»ä½•æŠ˜å ã€‚
3. å®¹é”™å¢å¼º: æ‰€æœ‰è®¡ç®—æ¨¡å—å¢åŠ ç‹¬ç«‹ try-exceptï¼Œåä¸€ä¸ªä¸å½±å“æ•´ä½“ã€‚
"""
import streamlit as st
import pandas as pd
import numpy as np
import yfinance as yf
import requests
from datetime import datetime, timedelta
import platform
import warnings
import time
import re
import traceback 
import io
from firecrawl import Firecrawl 
from PIL import Image 

# --- é¡µé¢é…ç½® ---
st.set_page_config(
    page_title="ç¾è‚¡å´©ç›˜é¢„è­¦ç ”æŠ¥ (å®Œæ•´ç‰ˆ)",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="collapsed" # é»˜è®¤æ”¶èµ·ä¾§è¾¹æ ï¼Œä¸“æ³¨çœ‹æŠ¥å‘Š
)

# --- æ ·å¼å¢å¼º (ä»¿ç ”æŠ¥é£æ ¼) ---
st.markdown("""
<style>
    .main-header { font-size: 30px; font-weight: bold; color: #FFFFFF; background: #4B535C; padding: 15px; border-radius: 8px; text-align: center; margin-bottom: 20px; }
    .sub-header { font-size: 22px; font-weight: bold; color: #FFEE88; border-bottom: 2px solid #666; margin-top: 30px; padding-bottom: 5px; }
    .info-text { font-size: 16px; color: #E0E0E0; margin-bottom: 5px; }
    .highlight { background-color: #262730; padding: 10px; border-radius: 5px; border-left: 5px solid #FF4B4B; margin: 10px 0; }
    .success-box { background-color: #262730; padding: 10px; border-radius: 5px; border-left: 5px solid #2E8B57; margin: 10px 0; }
</style>
""", unsafe_allow_html=True)

# --- ä¾èµ–æ£€æŸ¥ ---
try:
    from fredapi import Fred
except ImportError:
    st.warning("âš ï¸ å»ºè®®å®‰è£… fredapi")

try:
    from google import genai
except ImportError:
    st.error("âŒ ä¸¥é‡é”™è¯¯ï¼šæœªæ‰¾åˆ° google-genai åº“")
    st.stop()

# ==========================================
# ã€API é…ç½®ã€‘
# ==========================================
try:
    GENAI_API_KEY = st.secrets["GENAI_API_KEY"]
    USER_FRED_KEY = st.secrets.get("FRED_KEY", st.secrets.get("USER_FRED_KEY", ""))
    FIRECRAWL_KEY = st.secrets["FIRECRAWL_KEY"]
except Exception as e:
    st.error(f"âŒ Secrets é…ç½®é”™è¯¯: {e}")
    st.stop()

client = genai.Client(api_key=GENAI_API_KEY)
warnings.filterwarnings("ignore")

# ==========================================
# ã€UI è¾“å‡ºå‡½æ•° (å¢å¼ºç‰ˆ)ã€‘
# ==========================================
def print_h(msg): 
    st.markdown(f"<div class='sub-header'>{msg}</div>", unsafe_allow_html=True)

def print_step(msg): 
    st.write(f"ğŸ”¹ {msg}")

def print_ok(msg): 
    st.success(f"âœ… {msg}")

def print_warn(msg): 
    st.warning(f"âš ï¸ {msg}")

def print_err(msg): 
    st.error(f"âŒ {msg}")

# ==========================================
# ã€ç¼“å­˜å±‚ã€‘
# ==========================================
@st.cache_data(ttl=86400)
def get_cached_tickers():
    try:
        url = "https://en.wikipedia.org/wiki/List_of_S%26P_500_companies"
        tables = pd.read_html(requests.get(url, headers={"User-Agent": "Mozilla/5.0"}, timeout=15).text)
        for t in tables:
            if 'Symbol' in t.columns:
                return t['Symbol'].str.replace('.', '-', regex=False).tolist()
    except: return []

@st.cache_data(ttl=3600)
def get_cached_sp500_data(tickers):
    if not tickers: return pd.DataFrame()
    
    # ç®€å•çš„æ–‡æœ¬è¿›åº¦æç¤ºï¼Œä¸é˜»å¡ UI
    st.write(f"â³ æ­£åœ¨åå°ä¸‹è½½ {len(tickers)} åªæˆåˆ†è‚¡æ•°æ®...")
    
    closes = []
    batch_size = 50
    total = len(tickers)
    
    # ä½¿ç”¨ st.empty() åŠ¨æ€åˆ·æ–°è¿›åº¦æ–‡å­—ï¼Œé¿å…åˆ·å±
    progress_text = st.empty()
    
    for i in range(0, total, batch_size):
        batch = tickers[i:i+batch_size]
        try:
            progress_text.text(f"ğŸ“¥ ä¸‹è½½è¿›åº¦: {i}/{total}...")
            data = yf.download(batch, period="5y", auto_adjust=True, progress=False, threads=True, timeout=30)
            if isinstance(data.columns, pd.MultiIndex):
                try: close = data['Close']
                except: close = data
            else: close = data
            closes.append(close)
            time.sleep(0.1)
        except: pass
    
    progress_text.empty() # ä¸‹è½½å®Œæ¸…é™¤æç¤º
    if not closes: return pd.DataFrame()
    return pd.concat(closes, axis=1).dropna(axis=1, how='all')

@st.cache_data(ttl=3600)
def get_cached_sector_data(tickers, start_date):
    return yf.download(tickers, start=start_date, progress=False, auto_adjust=False)

@st.cache_data(ttl=3600)
def get_cached_smt_data(tickers, period):
    return yf.download(tickers, period=period, auto_adjust=False, progress=False)

# ==========================================
# ã€WebScraper (ä¿æŒä¸å˜)ã€‘
# ==========================================
class WebScraper:
    def __init__(self):
        self.app = Firecrawl(api_key=FIRECRAWL_KEY)
        self.fred_key = USER_FRED_KEY
        self.cached_gdp = None 
        self.cached_nasdaq = None

    def fetch_shiller_pe(self):
        try:
            resp = self.app.scrape("https://www.multpl.com/shiller-pe", formats=['markdown'])
            match = re.search(r'Shiller PE Ratio.*?(\d{2}\.\d{1,2})', getattr(resp, 'markdown', ''), re.S | re.I)
            if match: return float(match.group(1))
        except: pass
        return None

    def fetch_fear_greed(self):
        try:
            resp = self.app.scrape("https://www.cnn.com/markets/fear-and-greed", formats=['markdown'])
            match = re.search(r'(?:Fear\s*&\s*Greed\s*Index|Current\s*Reading).*?(\d{1,3})', getattr(resp, 'markdown', ''), re.S | re.I)
            if match: return int(match.group(1)), "Fetched"
        except: pass
        return None, "Fail"

    def fetch_us_gdp(self):
        if self.cached_gdp: return self.cached_gdp
        try:
            if not self.fred_key: return None
            fred = Fred(api_key=self.fred_key)
            s = fred.get_series('GDP', sort_order='desc', limit=1)
            val = s.iloc[0] / 1000.0
            self.cached_gdp = val
            return val
        except: return None

    def fetch_buffett_indicator(self):
        gdp = self.fetch_us_gdp()
        if not gdp: return None
        try:
            hist = yf.Ticker("^W5000").history(period="5d")
            if not hist.empty:
                return (hist['Close'].iloc[-1] / (gdp * 1000.0)) * 100
        except: pass
        return None

    def fetch_margin_debt(self):
        gdp = self.fetch_us_gdp()
        try:
            resp = self.app.scrape("https://www.finra.org/rules-guidance/key-topics/margin-accounts/margin-statistics", formats=['markdown'])
            matches = re.findall(r'([A-Z][a-z]{2}-\d{2})\s*\|\s*([\d,]+)', getattr(resp, 'markdown', ''), re.S | re.I)
            if matches:
                val_str = matches[0][1]
                debt = float(val_str.replace(',', '')) / 1_000_000
                ratio = (debt / gdp * 100) if gdp else None
                yoy = None
                if len(matches) >= 13:
                    prev = float(matches[12][1].replace(',', ''))
                    curr = float(val_str.replace(',', ''))
                    yoy = ((curr - prev) / prev) * 100
                return yoy, debt, ratio
        except: pass
        return None, None, None

    def fetch_sahm_rule(self):
        try:
            resp = self.app.scrape("https://fred.stlouisfed.org/series/SAHMREALTIME", formats=['markdown'])
            match = re.search(r'([A-Z][a-z]{2}\s+\d{4}):\s*([\d\.]+)', getattr(resp, 'markdown', ''), re.S | re.I)
            if match: return float(match.group(2))
        except: pass
        return None

    def fetch_lei(self):
        try:
            resp = self.app.scrape("https://www.conference-board.org/topics/us-leading-indicators", formats=['markdown'])
            md = getattr(resp, 'markdown', '')
            img_url = None
            if md:
                imgs = re.findall(r'\((https://.*?lei.*?\.png)\)', md, re.I)
                if imgs: img_url = imgs[0]
            if img_url:
                content = requests.get(img_url, headers={"User-Agent": "Mozilla/5.0"}).content
                img = Image.open(io.BytesIO(content))
                prompt = 'Extract "6-Month % Change" (depth) and "Diffusion" value. JSON: {"depth": -2.1, "diffusion": 35.0}'
                ai = client.models.generate_content(model='gemini-2.0-flash', contents=[prompt, img])
                js = json.loads(re.search(r'\{.*\}', ai.text, re.DOTALL).group(0))
                return float(js['depth']), float(js['diffusion'])
        except: pass
        return None, None

    def fetch_nyse_internals_robust(self):
        try:
            headers = {"Authorization": f"Bearer {FIRECRAWL_KEY}", "Content-Type": "application/json"}
            payload = {"url": "https://www.wsj.com/market-data/stocks/marketsdiary", "formats": ["markdown"], "waitFor": 5000}
            resp = requests.post("https://api.firecrawl.dev/v1/scrape", headers=headers, json=payload, timeout=60)
            if resp.status_code == 200:
                md = resp.json().get('data', {}).get('markdown', '')
                if md:
                    prompt = f"Extract NYSE and NASDAQ breadth data. Return JSON. Markdown: {md[:15000]}"
                    ai = client.models.generate_content(model='gemini-2.0-flash', contents=[prompt])
                    js = json.loads(re.search(r'\{.*\}', ai.text, re.DOTALL).group(0))
                    self.cached_nasdaq = js.get('NASDAQ')
                    return js.get('NYSE')
        except: pass
        return None

    def fetch_dual_mco(self):
        mco, nymo = None, None
        try:
            resp = self.app.scrape("https://www.mcoscillator.com/", formats=['markdown'])
            match = re.search(r'McC\s*OSC\s*\|?\s*([-\d\.]+)', getattr(resp, 'markdown', ''), re.I)
            if match: mco = float(match.group(1))
            
            headers = {"Authorization": f"Bearer {FIRECRAWL_KEY}", "Content-Type": "application/json"}
            payload = {"url": "https://stockcharts.com/h-sc/ui?s=$NYMO", "formats": ["screenshot"], "waitFor": 6000}
            r = requests.post("https://api.firecrawl.dev/v1/scrape", headers=headers, json=payload, timeout=60)
            if r.status_code == 200:
                url = r.json().get('data', {}).get('screenshot', '')
                if url:
                    img = Image.open(io.BytesIO(requests.get(url).content))
                    prompt = 'Extract $NYMO value. JSON: {"value": -12.3}'
                    ai = client.models.generate_content(model='gemini-2.0-flash', contents=[prompt, img])
                    nymo = float(json.loads(re.search(r'\{.*\}', ai.text, re.DOTALL).group(0)).get('value'))
        except: pass
        return mco, nymo

    def fetch_tv_breadth_vision(self):
        if hasattr(self, 'cached_nasdaq') and self.cached_nasdaq:
            try:
                def c(v): return int(float(str(v).replace(',','').replace('K','000'))) if v else 0
                return c(self.cached_nasdaq.get('adv')), c(self.cached_nasdaq.get('dec'))
            except: pass
        return None, None

    def fetch_pcr_robust(self):
        try:
            resp = self.app.scrape("https://en.macromicro.me/charts/449/us-cboe-options-put-call-ratio", formats=['markdown'])
            matches = re.findall(r'(\d{1,2}\.\d{2})', getattr(resp, 'markdown', ''))
            if matches: 
                val = float(matches[0])
                return val, val
        except: pass
        return None, None

    def fetch_nfci(self):
        try:
            if not self.fred_key: return None
            f = Fred(api_key=self.fred_key)
            s = f.get_series('NFCI', sort_order='desc', limit=1)
            return float(s.iloc[0])
        except: return None

# ==========================================
# ã€æ ¸å¿ƒç¨‹åºã€‘
# ==========================================
class CrashWarningSystem:
    def __init__(self):
        self.scraper = WebScraper()
        self.shared_wsj_data = None

    def calculate_spx_breadth_deep(self):
        tickers = get_cached_tickers()
        data = get_cached_sp500_data(tickers)
        if data.empty: return None, None
        
        last = data.iloc[-1]
        pct50 = (last > data.rolling(50).mean().iloc[-1]).mean() * 100
        pct20 = (last > data.rolling(20).mean().iloc[-1]).mean() * 100
        return pct50, pct20

    def analyze_market_trends_console(self):
        print_h("1. æ·±åº¦å®è§‚ä¸è¶‹åŠ¿åˆ†æ (Deep Macro)")
        if not USER_FRED_KEY: 
            st.warning("Fred Key æœªé…ç½®ï¼Œè·³è¿‡éƒ¨åˆ†å®è§‚æ•°æ®")
            return
        
        col1, col2, col3 = st.columns(3)
        try:
            fred = Fred(api_key=USER_FRED_KEY)
            # 1. å‡€æµåŠ¨æ€§
            with col1:
                start = datetime.now() - timedelta(weeks=5)
                walcl = fred.get_series('WALCL', observation_start=start).iloc[-1]
                tga = fred.get_series('WTREGEN', observation_start=start).iloc[-1]
                rrp = fred.get_series('RRPONTSYD', observation_start=start).iloc[-1]
                liq = (walcl/1e6) - (tga/1e3) - (rrp/1e3)
                st.metric("ç¾è”å‚¨å‡€æµåŠ¨æ€§", f"${liq:.3f}T", help="è§„åˆ™: æµåŠ¨æ€§å¢åŠ  = è‚¡å¸‚ç‡ƒæ–™å¢åŠ ")

            # 2. ERP
            with col2:
                dgs10 = fred.get_series('DGS10', sort_order='desc', limit=1).iloc[-1]
                pe = self.scraper.fetch_shiller_pe() or 35.0
                erp = (1.0/pe*100) - dgs10
                st.metric("è‚¡æƒé£é™©æº¢ä»· (ERP)", f"{erp:.2f}%", delta_color="normal" if erp>2.5 else "inverse")
                
            # 3. RSP/SPY
            with col3:
                try:
                    df = yf.download(['SPY', 'RSP'], period="3mo", progress=False)['Close']
                    if not df.empty:
                        ratio = df['RSP'] / df['SPY']
                        chg = ((ratio.iloc[-1] - ratio.iloc[-20]) / ratio.iloc[-20]) * 100
                        st.metric("RSP/SPY ç›¸å¯¹å¼ºåº¦(20d)", f"{chg:+.2f}%")
                        if df['SPY'].iloc[-1] > df['SPY'].iloc[-20] and chg < -1.0:
                            st.caption("ğŸ”´ ä¸¥é‡èƒŒç¦» (å¤§ç¥¨æ¶¨,å°ç¥¨è·Œ)")
                        else:
                            st.caption("ğŸŸ¢ ç»“æ„å¥åº·")
                except: st.write("RSPæ•°æ®ä¸è¶³")
        except: st.error("å®è§‚æ•°æ®è®¡ç®—å¤±è´¥")

    def fetch_and_calculate(self):
        # 1. å¹¿åº¦è®¡ç®—
        print_step("æ­£åœ¨è®¡ç®—å…¨å¸‚åœºå¹¿åº¦ (SMA50/SMA20)...")
        ma50_pct, ma20_pct = self.calculate_spx_breadth_deep()
        
        # 2. åŸºç¡€æ•°æ®
        tickers = yf.Tickers("^GSPC ^VIX ^TNX ^IRX RSP SPY ^NYA")
        hist = tickers.history(period="3y", group_by='ticker')
        spx = hist['^GSPC']['Close'].dropna()
        vix = hist['^VIX']['Close'].dropna()
        tnx = hist['^TNX']['Close'].dropna()
        irx = hist['^IRX']['Close'].dropna()
        rsp = hist['RSP']['Close'].dropna()
        spy = hist['SPY']['Close'].dropna()
        nya = hist['^NYA']['Close'].dropna()
        spx_weekly = spx.resample('W').last().dropna()
        spx_trend_up = spx.iloc[-1] > spx.rolling(50).mean().iloc[-1]
        
        # 3. çˆ¬è™«æ•°æ® (å¹¶è¡ŒæŠ“å–)
        print_step("æ­£åœ¨å¯åŠ¨ Firecrawl æŠ“å–å¤šæºæ•°æ®...")
        pe = self.scraper.fetch_shiller_pe()
        sahm = self.scraper.fetch_sahm_rule()
        fg, fg_src = self.scraper.fetch_fear_greed()
        buffett = self.scraper.fetch_buffett_indicator()
        m_yoy, m_amt, m_ratio = self.scraper.fetch_margin_debt()
        lei_d, lei_dif = self.scraper.fetch_lei()
        pcr_avg, pcr_cur = self.scraper.fetch_pcr_robust()
        nfci = self.scraper.fetch_nfci()
        
        print_step("æ­£åœ¨åˆ†æå¸‚åœºå†…éƒ¨ç»“æ„ (HO, MCO)...")
        mco, nymo = self.scraper.fetch_dual_mco()
        ho_res = self.scraper.fetch_nyse_internals_robust()
        if ho_res: self.shared_wsj_data = ho_res
        tv_adv, tv_dec = self.scraper.fetch_tv_breadth_vision()

        # ==================================================
        # ã€å…³é”®ä¿®å¤ã€‘å®šä¹‰åˆå§‹å˜é‡ï¼Œé˜²æ­¢ UnboundLocalError
        # ==================================================
        adv, dec, adv_v, dec_v = 0, 0, 0, 0
        h_pct, l_pct = 0, 0
        trin_val = 0
        
        if ho_res:
            def c(v): return float(str(v).replace(',','').replace('B','e9').replace('M','e6')) if v else 0
            adv = c(ho_res.get('adv')); dec = c(ho_res.get('dec'))
            adv_v = c(ho_res.get('adv_vol')); dec_v = c(ho_res.get('dec_vol'))
            
            # --- æ·±åº¦ TRIN åˆ†æ (åŸæ ·ä¿ç•™) ---
            if dec > 0 and dec_v > 0:
                trin_val = (adv / dec) / (adv_v / dec_v)
                st.markdown("---")
                st.markdown(f"#### ğŸ” TRIN æŒ‡æ ‡æ·±åº¦åˆ†æ (å½“å‰: `{trin_val:.2f}`)")
                
                status_desc = ""
                if trin_val < 0.5: status_desc = "ğŸ”´ **æåº¦å¼ºåŠ¿/ä¸¥é‡è¶…ä¹° (<0.5)** -> è­¦æƒ•é¡¶éƒ¨"
                elif 0.5 <= trin_val <= 0.8: status_desc = "ğŸŸ¢ **å¼ºåŠ¿/ä¹°æ–¹ä¸»å¯¼ (0.5-0.8)** -> å¥åº·ä¸Šæ¶¨"
                elif 0.8 < trin_val <= 1.2: status_desc = "ğŸŸ¢ **ä¸­æ€§/å¹³è¡¡ (0.8-1.2)** -> è§‚æœ›/è·Ÿéš"
                elif 1.2 < trin_val <= 2.0: status_desc = "ğŸŸ¡ **å¼±åŠ¿/å–å‹æ˜¾ç° (1.2-2.0)** -> è°¨æ…å‡ä»“"
                elif trin_val > 2.0: status_desc = "ğŸ”´ **æåº¦ææ…Œ/è¶…å– (>2.0)** -> æŠ„åº•æœºä¼š"
                
                st.write(f"ğŸ‘‰ **çŠ¶æ€åˆ¤å®š:** {status_desc}")
                
                if spx_trend_up:
                    if trin_val < 1.0: st.success("ğŸ“ˆ è¶‹åŠ¿é…åˆ: SPXä¸Šæ¶¨ + TRIN<1.0 (ä¹°æ°”å……è¶³ï¼Œå¥åº·)")
                    elif trin_val > 1.2: st.warning("ğŸ“‰ é‡ä»·èƒŒç¦»: SPXä¸Šæ¶¨ + TRIN>1.2 (ä»·æ ¼æ¶¨ä½†å†…éƒ¨è™šå¼±)")
                
                st.markdown("> **å£è¯€:** ä½äº0.5è¦å½“å¿ƒ(è§é¡¶)ï¼Œé«˜äº2.0è¦æ¿€åŠ¨(æŠ„åº•)ï¼")
                st.markdown("---")

        # --- æŒ‡æ ‡åˆ¤å®š ---
        indicators = []
        
        # 1. HO
        ho_stat = 0; ho_txt = "æ•°æ®ä¸è¶³"
        if ho_res:
            h = c(ho_res.get('high')); l = c(ho_res.get('low'))
            total = adv + dec + c(ho_res.get('unch', 0))
            if total > 0:
                h_pct = (h/total)*100
                l_pct = (l/total)*100
            
            split = (h_pct > 2.2 and l_pct > 2.2)
            mco_bad = (mco < 0) if mco else (adv < dec)
            if spx_trend_up and split and mco_bad: ho_stat = 2
            elif split: ho_stat = 1
            ho_txt = f"æ–°é«˜:{h_pct:.1f}% | æ–°ä½:{l_pct:.1f}%"
        indicators.append(["Hindenburg Omen", ho_stat, ho_txt, "æ¡ä»¶: 50MAä¸Š & æ–°é«˜ä½>2.2% & MCO<0"])

        # 2. Net Issues
        net_stat = 0; net_issues = adv - dec
        if net_issues < -2000: net_stat = 2
        elif net_issues < -1000: net_stat = 1
        indicators.append(["æŠ›å‹ I: å¹¿åº¦ (Net)", net_stat, f"{net_issues:.0f}", "<-1000 æ˜¾è‘— | <-2000 ææ…Œ"])

        # 3. TRIN
        trin_stat = 0
        if dec > 0 and dec_v > 0:
            if trin_val < 0.5: trin_stat = 2
            elif trin_val > 2.0: trin_stat = 1
        indicators.append(["æŠ›å‹ II: åŠ›åº¦ (TRIN)", trin_stat, f"{trin_val:.2f}", "<0.5(æåº¦è¶…ä¹°) | >2.0(ææ…ŒæŠ„åº•)"])

        # 4. Vol Flow
        vol_stat = 0; vol_txt = "N/A"
        if adv_v > 0:
            ratio = dec_v / adv_v
            if ratio > 9.0: vol_stat = 2
            elif ratio > 4.0: vol_stat = 1
            vol_txt = f"Dn/Up: {ratio:.1f}"
        indicators.append(["æŠ›å‹ III: èµ„é‡‘ (Vol)", vol_stat, vol_txt, "Dn/Up > 4.0 å‡ºé€ƒ | > 9.0 æ´—ç›˜"])

        # 5. NASDAQ
        tv_stat = 0
        if tv_adv and tv_dec:
            ratio = tv_adv / tv_dec
            if ratio < 0.5: tv_stat = 2
            indicators.append(["NASDAQ A/D", tv_stat, f"{ratio:.2f}", "<0.5 ç©ºå¤´ä¸»å¯¼"])
        else: indicators.append(["NASDAQ A/D", 0, "N/A", ""])

        # 6. RSP
        try:
            r = rsp/spy
            curr, ma = r.iloc[-1], r.rolling(50).mean().iloc[-1]
            chg = (curr/r.iloc[-20]-1)*100
            st_rsp = 2 if (curr<ma and chg<-2.0) else (1 if curr<ma else 0)
            indicators.append(["RSP/SPY å¹¿åº¦", st_rsp, f"20æ—¥å˜åŠ¨: {chg:.1f}%", "è·Œç ´50MA & æ€¥è·Œ"])
        except: indicators.append(["RSP/SPY", 0, "Error", ""])
        
        # 7. NYA
        try:
            ok = nya.iloc[-1] > nya.rolling(50).mean().iloc[-1]
            st_nya = 2 if (spx_trend_up and not ok) else 0
            indicators.append(["NYA å‚ä¸åº¦", st_nya, "å¼±" if not ok else "å¼º", "SPXå¼ºä½†NYAå¼±"])
        except: pass

        # 8. å€’æŒ‚
        try:
            spr = tnx.iloc[-1] - irx.iloc[-1]
            indicators.append(["10Y-3M å€’æŒ‚", 2 if spr<0 else 0, f"{spr:.2f}%", "< 0%"])
        except: pass

        # 9-12 å®è§‚
        indicators.append(["Shiller PE", 2 if pe and pe>30 else 0, f"{pe}", ">30 é«˜ä¼°"])
        indicators.append(["å·´è²ç‰¹æŒ‡æ ‡", 2 if buffett and buffett>140 else 0, f"{buffett:.1f}%", ">140%"])
        indicators.append(["Margin Debt", 1 if m_ratio and m_ratio>3.5 else 0, f"GDPæ¯”:{m_ratio:.1f}%", ">3.5%"])
        
        # 13 VIX
        try:
            v = vix.iloc[-1]
            chg = (v/vix.iloc[-15]-1)*100
            st_vix = 2 if (v>25 or chg>40) else 0
            indicators.append(["VIX", st_vix, f"{v:.1f} (+{chg:.0f}%)", ">25 æˆ– é£™å‡"])
        except: pass

        # 14 å¹¿åº¦
        if ma50_pct:
            st_br = 2 if ma50_pct<40 else 0
            indicators.append(["SPX >50MA", st_br, f"{ma50_pct:.1f}%", "<40% å±é™©"])

        # 15 RSI
        try:
            delta = spx_weekly.diff()
            u = delta.clip(lower=0); d = -delta.clip(upper=0)
            rs = u.ewm(alpha=1/14).mean() / d.ewm(alpha=1/14).mean()
            rsi = 100 - 100/(1+rs)
            div = False
            if rsi.iloc[-1] < rsi.iloc[-5] and spx_weekly.iloc[-1] > spx_weekly.iloc[-5]: div = True
            indicators.append(["RSI å‘¨çº¿èƒŒç¦»", 2 if div else 0, f"{rsi.iloc[-1]:.1f}", "ä»·æ¶¨é‡ç¼©"])
        except: pass

        # 16 Support
        try:
            sma20 = spx_weekly.rolling(20).mean().iloc[-1]
            ema21 = spx_weekly.ewm(span=21).mean().iloc[-1]
            status = 2 if spx.iloc[-1] < min(sma20, ema21) else 0
            indicators.append(["ç‰›å¸‚æ”¯æ’‘å¸¦", status, f"ç°ä»·:{spx.iloc[-1]:.0f}", "è·Œç ´ 20SMA/21EMA"])
        except: pass

        # 17-21 å…¶ä»–
        indicators.append(["Fear & Greed", 2 if fg and fg<45 else 0, f"{fg}", "<45"])
        try:
            e12 = spx_weekly.ewm(span=12).mean(); e26 = spx_weekly.ewm(span=26).mean()
            macd = e12 - e26; sig = macd.ewm(span=9).mean()
            dead = (macd.iloc[-2]>sig.iloc[-2]) and (macd.iloc[-1]<sig.iloc[-1]) and (macd.iloc[-1]>0)
            indicators.append(["MACD å‘¨çº¿æ­»å‰", 2 if dead else 0, "æ­»å‰" if dead else "æ­£å¸¸", "é›¶è½´ä¸Šæ–¹æ­»å‰"])
        except: pass
        indicators.append(["Sahm Rule", 2 if sahm and sahm>=0.5 else 0, f"{sahm}%", ">=0.5%"])
        indicators.append(["LEI", 2 if lei_d and lei_d<-4.0 else 0, f"{lei_d}%", "<-4.0%"])
        indicators.append(["PCR", 2 if pcr_avg and pcr_avg<0.8 else 0, f"{pcr_avg}", "<0.8"])
        indicators.append(["NFCI", 2 if nfci and nfci>-0.2 else 0, f"{nfci}", ">-0.2"])
        nymo_st = 2 if nymo and (nymo>60 or nymo<-60) else 0
        indicators.append(["NYMO", nymo_st, f"{nymo}", "æç«¯å€¼ +/-60"])

        return indicators

    def generate_table(self):
        print_h("2. 21å› å­é£é™©ä»ªè¡¨ç›˜ (The 21 Factors)")
        data = self.fetch_and_calculate()
        
        risk_score = sum(1 for d in data if d[1] == 2) + sum(0.5 for d in data if d[1] == 1)
        
        st.markdown(f"<div class='main-header'>ç»¼åˆé£é™©è¯„åˆ†: {risk_score:.1f} / 21.0</div>", unsafe_allow_html=True)
        if risk_score <= 5: st.success("âœ… å¸‚åœºç»“æ„å¥åº·ï¼Œå¯ä¿æŒè§‚å¯Ÿ")
        elif risk_score <= 10: st.warning("ğŸŸ¡ ä¸­æœŸé£é™©ç´¯ç§¯ï¼Œå»ºè®®è°¨æ…")
        else: st.error("ğŸ”´ å´©ç›˜ä¿¡å·å…±æŒ¯ï¼Œå»ºè®®ç«‹å³å‡ä»“")
        
        df_display = []
        for row in data:
            name, stat, val, desc = row
            status_txt = "ğŸ”´ å±é™©" if stat==2 else ("ğŸŸ¡ è­¦å‘Š" if stat==1 else "ğŸŸ¢ å®‰å…¨")
            df_display.append({"ç›‘æµ‹æŒ‡æ ‡": name, "çŠ¶æ€": status_txt, "å½“å‰è¯»æ•°": val, "åˆ¤æ–­æ ‡å‡†": desc})
        
        st.table(pd.DataFrame(df_display))

# ==========================================
# ã€æ¿å—è½®åŠ¨ã€‘
# ==========================================
class SectorRotationEngine:
    def __init__(self):
        self.sectors = {'XLK': 'ç§‘æŠ€', 'XLF': 'é‡‘è', 'XLV': 'åŒ»ç–—', 'XLE': 'èƒ½æº', 'XLY': 'å¯é€‰', 
                       'XLP': 'å¿…é€‰', 'XLI': 'å·¥ä¸š', 'XLC': 'é€šè®¯', 'XLB': 'ææ–™', 'XLRE': 'åœ°äº§', 'SPY': 'åŸºå‡†'}
        self.rs_window = 60 
        self.mom_window = 10 

    def run_analysis(self):
        print_h("3. æ¿å—è½®åŠ¨åˆ†æ (Sector Rotation RRG)")
        tickers = list(self.sectors.keys())
        data = get_cached_sector_data(tickers, "2023-01-01")
        if data.empty: return
        
        closes = data['Adj Close'] if 'Adj Close' in data else data['Close']
        rs = closes.div(closes['SPY'], axis=0)
        
        ratio = 100 * (rs / rs.rolling(self.rs_window).mean())
        mom = 100 + ((rs - rs.shift(self.mom_window)) / rs.shift(self.mom_window) * 100)
        
        res = []
        for t in tickers:
            if t == 'SPY': continue
            r = ratio[t].iloc[-1]
            m = mom[t].iloc[-1]
            q = "æ»å"
            if r>100 and m>100: q = "ğŸŸ¢ é¢†æ¶¨ (Leading)"
            elif r<100 and m>100: q = "ğŸ”µ æ”¹å–„ (Improving)"
            elif r>100 and m<100: q = "ğŸŸ¡ è½¬å¼± (Weakening)"
            else: q = "ğŸ”´ è½å (Lagging)"
            res.append({"æ¿å—": self.sectors[t], "RS (è¶‹åŠ¿)": f"{r:.1f}", "Mom (åŠ¨é‡)": f"{m:.1f}", "è±¡é™": q})
            
        st.dataframe(pd.DataFrame(res), use_container_width=True)

# ==========================================
# ã€SMT èƒŒç¦»ã€‘
# ==========================================
class SMTDivergenceAnalyzer:
    def __init__(self):
        self.tickers = ['^IXIC', '^GSPC', 'QQQ', 'SPY', 'NQ=F', 'ES=F', 'RSP']

    def run(self):
        print_h("4. SMT èƒŒç¦»åˆ†æ (Smart Money Technique)")
        df = get_cached_smt_data(self.tickers, "6mo")
        if df.empty: return
        close = df['Close'].ffill()
        
        st.write("**(1) æœŸè´§å…ˆè¡ŒæŒ‡æ ‡ (NQ vs ES)**")
        st.caption("æœŸè´§åŒ…å«å¤œç›˜æ•°æ®ï¼Œæ¯” ETF ååº”æ›´æ•é”ã€‚")
        w = close.iloc[-10:]
        h = w.max(); curr = w.iloc[-1]
        
        if 'NQ=F' in w and 'ES=F' in w:
            nq_h = curr['NQ=F'] >= h['NQ=F']*0.999
            es_h = curr['ES=F'] >= h['ES=F']*0.999
            if nq_h and not es_h: 
                st.markdown("<div class='highlight'>ğŸ“‰ <b>çœ‹è·ŒèƒŒç¦»:</b> çº³æŒ‡æ‹‰å‡ï¼Œæ ‡æ™®æ»æ¶¨ (èµ„é‡‘è¯±å¤šç§‘æŠ€)</div>", unsafe_allow_html=True)
            elif not nq_h and es_h: 
                st.markdown("<div class='highlight'>ğŸ“‰ <b>çœ‹è·ŒèƒŒç¦»:</b> æ ‡æ™®è¡¥æ¶¨ï¼Œçº³æŒ‡åŠ¨èƒ½è¡°ç«­ (è¡Œæƒ…å°¾å£°)</div>", unsafe_allow_html=True)
            elif not nq_h and not es_h: 
                st.info("âšª æ­£å¸¸è°ƒæ•´ (æ— æ–°é«˜)")
            else: 
                st.success("ğŸŸ¢ æ­¥è°ƒä¸€è‡´ (åŒåŒæ–°é«˜ï¼Œè¶‹åŠ¿å¼ºåŠ²)")

        st.write("**(2) å†…éƒ¨å¹¿åº¦éªŒè¯ (SPY vs RSP)**")
        if 'SPY' in w and 'RSP' in w:
            spy_p = (curr['SPY']/w.iloc[0]['SPY']-1)*100
            rsp_p = (curr['RSP']/w.iloc[0]['RSP']-1)*100
            if spy_p > rsp_p and spy_p > 0 and rsp_p < 0:
                st.error(f"âš ï¸ è™šå‡ç¹è£: åªæœ‰å·¨å¤´åœ¨æ¶¨ (SPY +{spy_p:.1f}%), å¤§éƒ¨åˆ†è‚¡ç¥¨åœ¨è·Œ (RSP {rsp_p:.1f}%)")
            else:
                st.success(f"âœ… å¹¿åº¦å¥åº·: ç­‰æƒæŒ‡æ•°({rsp_p:.1f}%) ç¡®è®¤äº† å¤§ç›˜èµ°åŠ¿")

# ==========================================
# ã€ä¸»ç¨‹åºã€‘
# ==========================================
if __name__ == "__main__":
    st.sidebar.title("æ“ä½œå°")
    if st.sidebar.button("ğŸ”„ åˆ·æ–°æŠ¥å‘Š"):
        st.cache_data.clear()
        st.rerun()
        
    st.markdown(f"<div class='main-header'>ğŸš€ ç¾è‚¡å´©ç›˜é¢„è­¦ç³»ç»Ÿ Pro<br><span style='font-size:16px'>ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M')}</span></div>", unsafe_allow_html=True)
    
    app = CrashWarningSystem()
    
    # 1. æ·±åº¦å®è§‚
    app.analyze_market_trends_console()
    
    # 2. 21å› å­å¤§è¡¨ (æ ¸å¿ƒ)
    app.generate_table()
    
    # 3. è¡¥å……æ¨¡å‹
    sr = SectorRotationEngine()
    sr.run_analysis()
    
    smt = SMTDivergenceAnalyzer()
    smt.run()
    
    st.balloons()
    st.success("âœ… æ‰€æœ‰åˆ†æä»»åŠ¡æ‰§è¡Œå®Œæ¯•")
    st.stop()
