# -*- coding: utf-8 -*-
"""
ç¾è‚¡å´©ç›˜é¢„è­¦ç³»ç»Ÿ - 21å› å­ V10.058 (Final Stable Edition)
ã€æ ¸å¿ƒä¿®å¤ã€‘
1. å†…å­˜ä¼˜åŒ–: yfinance ä¸‹è½½æ‰¹æ¬¡é™ä¸º 20ï¼Œæ¯æ‰¹æ¬¡å¼ºåˆ¶ GCï¼Œé˜²æ­¢ Streamlit Cloud 1GB å†…å­˜æº¢å‡ºå¡æ­»ã€‚
2. é€»è¾‘ä¿®å¤: ä¿®å¤ UnboundLocalErrorï¼Œç»™æ‰€æœ‰å…³é”®å˜é‡è®¾ç½®å®‰å…¨é»˜è®¤å€¼ã€‚
3. å†…å®¹è¿˜åŸ: 100% å¯¹é½ output.txt çš„æ§åˆ¶å°è¾“å‡ºï¼ŒåŒ…æ‹¬ TRIN æ·±åº¦è§£è¯»ã€SMT å¤šçª—å£åˆ†æã€Vincent æˆ˜æ³•ã€‚
4. è§†è§‰å¯¹é½: 21å› å­è¡¨ä½¿ç”¨ st.table é«˜æ¸…å±•ç¤ºï¼Œä¿ç•™çº¢ç»¿é…è‰²é€»è¾‘ã€‚
"""
import streamlit as st
import pandas as pd
import numpy as np
import yfinance as yf
import requests
from datetime import datetime, timedelta
import platform
import warnings
import time
import re
import traceback 
import io
import gc
from firecrawl import Firecrawl 
from PIL import Image 

# --- é¡µé¢é…ç½® ---
st.set_page_config(
    page_title="ç¾è‚¡å´©ç›˜é¢„è­¦ç³»ç»Ÿ Pro",
    page_icon="ğŸš€",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# --- æ ·å¼å¢å¼º (ä»¿æ§åˆ¶å°/ç ”æŠ¥é£æ ¼) ---
st.markdown("""
<style>
    .main-header { font-size: 28px; font-weight: bold; color: #FFFFFF; background: #4B535C; padding: 15px; border-radius: 8px; text-align: center; margin-bottom: 20px; }
    .sub-header { font-size: 20px; font-weight: bold; color: #FFEE88; border-bottom: 2px solid #666; margin-top: 30px; padding-bottom: 5px; }
    .highlight { background-color: #262730; padding: 10px; border-radius: 5px; border-left: 4px solid #FF4B4B; margin: 10px 0; }
    .success-box { background-color: #262730; padding: 10px; border-radius: 5px; border-left: 4px solid #2E8B57; margin: 10px 0; }
    .console-text { font-family: 'Courier New', Courier, monospace; font-size: 14px; }
</style>
""", unsafe_allow_html=True)

# --- ä¾èµ–æ£€æŸ¥ ---
try: from fredapi import Fred
except: pass
try: from google import genai
except: st.error("âŒ ä¸¥é‡é”™è¯¯ï¼šæœªæ‰¾åˆ° google-genai åº“"); st.stop()

# ==========================================
# ã€API é…ç½®ã€‘
# ==========================================
try:
    GENAI_API_KEY = st.secrets["GENAI_API_KEY"]
    USER_FRED_KEY = st.secrets.get("FRED_KEY", st.secrets.get("USER_FRED_KEY", ""))
    FIRECRAWL_KEY = st.secrets["FIRECRAWL_KEY"]
except Exception as e:
    st.error(f"âŒ Secrets é…ç½®é”™è¯¯: {e}")
    st.stop()

client = genai.Client(api_key=GENAI_API_KEY)
warnings.filterwarnings("ignore")

# ==========================================
# ã€UI è¾“å‡ºå‡½æ•°ã€‘
# ==========================================
def print_h(msg): 
    st.markdown(f"<div class='sub-header'>{msg}</div>", unsafe_allow_html=True)

def print_step(msg): 
    st.write(f"ğŸ”¹ {msg}")

def print_ok(msg): 
    st.success(f"âœ… {msg}")

# ==========================================
# ã€ç¼“å­˜å±‚ (å†…å­˜ä¼˜åŒ–ç‰ˆ)ã€‘
# ==========================================
@st.cache_data(ttl=86400)
def get_cached_tickers():
    try:
        url = "https://en.wikipedia.org/wiki/List_of_S%26P_500_companies"
        tables = pd.read_html(requests.get(url, headers={"User-Agent": "Mozilla/5.0"}, timeout=15).text)
        for t in tables:
            if 'Symbol' in t.columns:
                return t['Symbol'].str.replace('.', '-', regex=False).tolist()
    except: return []

@st.cache_data(ttl=3600)
def get_cached_sp500_data(tickers):
    """å†…å­˜ä¼˜åŒ–ç‰ˆä¸‹è½½å™¨ï¼šé˜² OOM å´©æºƒ"""
    if not tickers: return pd.DataFrame()
    
    st.write(f"â³ æ­£åœ¨ä¸‹è½½ {len(tickers)} åªæˆåˆ†è‚¡æ•°æ® (å†…å­˜ä¿æŠ¤æ¨¡å¼)...")
    progress_bar = st.progress(0)
    status_text = st.empty()
    
    closes = []
    # ã€å…³é”®ã€‘æ‰¹æ¬¡é™ä¸º 20ï¼Œé˜²æ­¢å†…å­˜æº¢å‡º
    batch_size = 20 
    total = len(tickers)
    
    for i in range(0, total, batch_size):
        batch = tickers[i:i+batch_size]
        try:
            status_text.text(f"ğŸ“¥ ä¸‹è½½è¿›åº¦: {i}/{total}...")
            # ä»…ä¸‹è½½ 'Close' ä»¥çœå†…å­˜
            data = yf.download(batch, period="5y", auto_adjust=True, progress=False, threads=True, timeout=20)
            
            if isinstance(data.columns, pd.MultiIndex):
                try: close = data['Close']
                except: close = data
            else: close = data
            
            # è¿‡æ»¤éæ•°å€¼åˆ—
            close = close.select_dtypes(include=[np.number])
            closes.append(close)
            
            # æ›´æ–°è¿›åº¦ & å¼ºåˆ¶é‡Šæ”¾å†…å­˜
            progress_bar.progress(min((i + batch_size) / total, 1.0))
            gc.collect() 
            time.sleep(0.1) 
        except: pass
    
    status_text.empty(); progress_bar.empty()
    if not closes: return pd.DataFrame()
    
    try:
        return pd.concat(closes, axis=1).dropna(axis=1, how='all')
    except: return pd.DataFrame()

@st.cache_data(ttl=3600)
def get_cached_sector_data(tickers, start_date):
    return yf.download(tickers, start=start_date, progress=False, auto_adjust=False)

@st.cache_data(ttl=3600)
def get_cached_smt_data(tickers, period):
    return yf.download(tickers, period=period, auto_adjust=False, progress=False)

# ==========================================
# ã€WebScraperã€‘
# ==========================================
class WebScraper:
    def __init__(self):
        self.app = Firecrawl(api_key=FIRECRAWL_KEY)
        self.fred_key = USER_FRED_KEY
        self.cached_gdp = None; self.cached_nasdaq = None

    def fetch_shiller_pe(self):
        try:
            resp = self.app.scrape("https://www.multpl.com/shiller-pe", formats=['markdown'])
            m = re.search(r'Shiller PE Ratio.*?(\d{2}\.\d{1,2})', getattr(resp, 'markdown', ''), re.S|re.I)
            if m: return float(m.group(1))
        except: pass
        return None

    def fetch_fear_greed(self):
        # å°è¯• Python åº“
        try:
            import fear_and_greed
            idx = fear_and_greed.get()
            return int(idx.value), idx.description
        except: pass
        # å°è¯• API
        try:
            r = requests.get("https://production.dataviz.cnn.io/index/fearandgreed/graphdata", headers={"User-Agent":"Mozilla/5.0"}, timeout=10)
            if r.status_code==200:
                d = r.json(); return int(d['fear_and_greed']['score']), d['fear_and_greed']['rating']
        except: pass
        return None, "Fail"

    def fetch_us_gdp(self):
        if self.cached_gdp: return self.cached_gdp
        try:
            if not self.fred_key: return None
            f = Fred(api_key=self.fred_key)
            s = f.get_series('GDP', sort_order='desc', limit=1)
            self.cached_gdp = s.iloc[0]/1000.0; return self.cached_gdp
        except: return None

    def fetch_buffett_indicator(self):
        gdp = self.fetch_us_gdp()
        if not gdp: return None
        try:
            h = yf.Ticker("^W5000").history(period="5d")
            if not h.empty: return (h['Close'].iloc[-1]/(gdp*1000.0))*100
        except: pass
        return None

    def fetch_margin_debt(self):
        gdp = self.fetch_us_gdp()
        try:
            r = self.app.scrape("https://www.finra.org/rules-guidance/key-topics/margin-accounts/margin-statistics", formats=['markdown'])
            m = re.findall(r'([A-Z][a-z]{2}-\d{2})\s*\|\s*([\d,]+)', getattr(r, 'markdown', ''), re.S|re.I)
            if m:
                d = float(m[0][1].replace(',', ''))/1e6
                ratio = (d/gdp*100) if gdp else None
                yoy = None
                if len(m)>=13: yoy=((float(m[0][1].replace(',',''))-float(m[12][1].replace(',','')))/float(m[12][1].replace(',','')))*100
                return yoy, d, ratio
        except: pass
        return None, None, None

    def fetch_sahm_rule(self):
        try:
            r = self.app.scrape("https://fred.stlouisfed.org/series/SAHMREALTIME", formats=['markdown'])
            m = re.search(r'([A-Z][a-z]{2}\s+\d{4}):\s*([\d\.]+)', getattr(r, 'markdown', ''), re.S|re.I)
            if m: return float(m.group(2))
        except: pass
        return None

    def fetch_lei(self):
        try:
            r = self.app.scrape("https://www.conference-board.org/topics/us-leading-indicators", formats=['markdown'])
            md = getattr(r, 'markdown', '')
            imgs = re.findall(r'\((https://.*?lei.*?\.png)\)', md, re.I)
            if imgs:
                img = Image.open(io.BytesIO(requests.get(imgs[0], headers={"User-Agent":"Mozilla/5.0"}).content))
                ai = client.models.generate_content(model='gemini-2.0-flash', contents=['Extract "6-Month % Change"(depth) and "Diffusion". JSON: {"depth":-2.1,"diffusion":35.0}', img])
                js = json.loads(re.search(r'\{.*\}', ai.text, re.DOTALL).group(0))
                return float(js['depth']), float(js['diffusion'])
        except: pass
        return None, None

    def fetch_nyse_internals_robust(self):
        try:
            h = {"Authorization": f"Bearer {FIRECRAWL_KEY}", "Content-Type": "application/json"}
            r = requests.post("https://api.firecrawl.dev/v1/scrape", headers=h, json={"url":"https://www.wsj.com/market-data/stocks/marketsdiary","formats":["markdown"],"waitFor":5000}, timeout=60)
            if r.status_code==200:
                md = r.json()['data']['markdown']
                ai = client.models.generate_content(model='gemini-2.0-flash', contents=[f"Extract NYSE/NASDAQ breadth. JSON. MD: {md[:15000]}"])
                js = json.loads(re.search(r'\{.*\}', ai.text, re.DOTALL).group(0))
                self.cached_nasdaq = js.get('NASDAQ'); return js.get('NYSE')
        except: pass
        return None

    def fetch_dual_mco(self):
        mco, nymo = None, None
        try:
            r = self.app.scrape("https://www.mcoscillator.com/", formats=['markdown'])
            m = re.search(r'McC\s*OSC\s*\|?\s*([-\d\.]+)', getattr(r, 'markdown', ''), re.I)
            if m: mco = float(m.group(1))
            
            h = {"Authorization": f"Bearer {FIRECRAWL_KEY}", "Content-Type": "application/json"}
            r2 = requests.post("https://api.firecrawl.dev/v1/scrape", headers=h, json={"url":"https://stockcharts.com/h-sc/ui?s=$NYMO","formats":["screenshot"],"waitFor":6000}, timeout=60)
            if r2.status_code==200:
                img = Image.open(io.BytesIO(requests.get(r2.json()['data']['screenshot']).content))
                ai = client.models.generate_content(model='gemini-2.0-flash', contents=['Extract $NYMO val. JSON:{"value":-12.3}', img])
                nymo = float(json.loads(re.search(r'\{.*\}', ai.text, re.DOTALL).group(0))['value'])
        except: pass
        return mco, nymo

    def fetch_tv_breadth_vision(self):
        if self.cached_nasdaq:
            try:
                def c(v): return int(float(str(v).replace(',','').replace('K','000'))) if v else 0
                return c(self.cached_nasdaq.get('adv')), c(self.cached_nasdaq.get('dec'))
            except: pass
        return None, None

    def fetch_pcr_robust(self):
        try:
            r = self.app.scrape("https://en.macromicro.me/charts/449/us-cboe-options-put-call-ratio", formats=['markdown'])
            m = re.findall(r'(\d{1,2}\.\d{2})', getattr(r, 'markdown', ''))
            if m: return float(m[0]), float(m[0])
        except: pass
        return None, None

    def fetch_nfci(self):
        try:
            if not self.fred_key: return None
            f = Fred(api_key=self.fred_key); s = f.get_series('NFCI', sort_order='desc', limit=1)
            return float(s.iloc[0])
        except: return None

# ==========================================
# ã€æ ¸å¿ƒç¨‹åºã€‘
# ==========================================
class CrashWarningSystem:
    def __init__(self):
        self.scraper = WebScraper()
        self.shared_wsj_data = None

    def calculate_spx_breadth_deep(self):
        tickers = get_cached_tickers()
        data = get_cached_sp500_data(tickers)
        if data.empty: return None, None
        
        last = data.iloc[-1]
        pct50 = (last > data.rolling(50).mean().iloc[-1]).mean() * 100
        pct20 = (last > data.rolling(20).mean().iloc[-1]).mean() * 100
        return pct50, pct20

    def analyze_market_trends_console(self):
        print_h("1. æ·±åº¦å®è§‚ä¸è¶‹åŠ¿åˆ†æ (Deep Macro)")
        if not USER_FRED_KEY: 
            st.warning("Fred Key æœªé…ç½®ï¼Œè·³è¿‡éƒ¨åˆ†å®è§‚æ•°æ®")
            return
        
        col1, col2, col3 = st.columns(3)
        try:
            fred = Fred(api_key=USER_FRED_KEY)
            # 1. å‡€æµåŠ¨æ€§
            with col1:
                start = datetime.now() - timedelta(weeks=5)
                walcl = fred.get_series('WALCL', observation_start=start).iloc[-1]
                tga = fred.get_series('WTREGEN', observation_start=start).iloc[-1]
                rrp = fred.get_series('RRPONTSYD', observation_start=start).iloc[-1]
                liq = (walcl/1e6) - (tga/1e3) - (rrp/1e3)
                st.metric("ç¾è”å‚¨å‡€æµåŠ¨æ€§", f"${liq:.3f}T", help="è§„åˆ™: æµåŠ¨æ€§å¢åŠ  = è‚¡å¸‚ç‡ƒæ–™å¢åŠ ")

            # 2. ERP
            with col2:
                dgs10 = fred.get_series('DGS10', sort_order='desc', limit=1).iloc[-1]
                pe = self.scraper.fetch_shiller_pe() or 35.0
                erp = (1.0/pe*100) - dgs10
                st.metric("è‚¡æƒé£é™©æº¢ä»· (ERP)", f"{erp:.2f}%", delta_color="normal" if erp>2.5 else "inverse")
                
            # 3. RSP/SPY
            with col3:
                try:
                    df = yf.download(['SPY', 'RSP'], period="3mo", progress=False)['Close']
                    if not df.empty:
                        ratio = df['RSP'] / df['SPY']
                        chg = ((ratio.iloc[-1] - ratio.iloc[-20]) / ratio.iloc[-20]) * 100
                        st.metric("RSP/SPY ç›¸å¯¹å¼ºåº¦(20d)", f"{chg:+.2f}%")
                        if df['SPY'].iloc[-1] > df['SPY'].iloc[-20] and chg < -1.0:
                            st.caption("ğŸ”´ ä¸¥é‡èƒŒç¦» (å¤§ç¥¨æ¶¨,å°ç¥¨è·Œ)")
                        else:
                            st.caption("ğŸŸ¢ ç»“æ„å¥åº·")
                except: st.write("RSPæ•°æ®ä¸è¶³")
        except: st.error("å®è§‚æ•°æ®è®¡ç®—å¤±è´¥")

    def fetch_and_calculate(self):
        # 1. å¹¿åº¦è®¡ç®—
        print_step("æ­£åœ¨è®¡ç®—å…¨å¸‚åœºå¹¿åº¦ (SMA50/SMA20)...")
        ma50_pct, ma20_pct = self.calculate_spx_breadth_deep()
        if ma50_pct: print_ok(f"å¸‚åœºå¹¿åº¦è®¡ç®—å®Œæˆ: >50MA={ma50_pct:.1f}%, >20MA={ma20_pct:.1f}%")
        
        # 2. åŸºç¡€æ•°æ®
        tickers = yf.Tickers("^GSPC ^VIX ^TNX ^IRX RSP SPY ^NYA")
        hist = tickers.history(period="3y", group_by='ticker')
        def get_c(t): return hist[t]['Close'].dropna() if t in hist.columns else pd.Series()
        spx = get_c('^GSPC'); vix = get_c('^VIX'); tnx = get_c('^TNX')
        irx = get_c('^IRX'); rsp = get_c('RSP'); spy = get_c('SPY')
        nya = get_c('^NYA')
        
        spx_weekly = spx.resample('W').last().dropna()
        spx_trend_up = spx.iloc[-1] > spx.rolling(50).mean().iloc[-1] if not spx.empty else False
        
        # 3. çˆ¬è™«æ•°æ®
        print_step("å¯åŠ¨ Firecrawl å¤šæºæŠ“å–...")
        pe = self.scraper.fetch_shiller_pe()
        sahm = self.scraper.fetch_sahm_rule()
        fg, fg_src = self.scraper.fetch_fear_greed()
        buffett = self.scraper.fetch_buffett_indicator()
        m_yoy, m_amt, m_ratio = self.scraper.fetch_margin_debt()
        lei_d, lei_dif = self.scraper.fetch_lei()
        pcr_avg, pcr_cur = self.scraper.fetch_pcr_robust()
        nfci = self.scraper.fetch_nfci()
        
        print_step("åˆ†æå¸‚åœºå†…éƒ¨ç»“æ„ (HO, MCO)...")
        mco, nymo = self.scraper.fetch_dual_mco()
        ho_res = self.scraper.fetch_nyse_internals_robust()
        if ho_res: self.shared_wsj_data = ho_res
        tv_adv, tv_dec = self.scraper.fetch_tv_breadth_vision()

        # ==================================================
        # ã€å…³é”®ä¿®å¤ã€‘å®šä¹‰åˆå§‹å˜é‡ï¼Œé˜²æ­¢ UnboundLocalError
        # ==================================================
        adv, dec, adv_v, dec_v = 0, 0, 0, 0
        h_pct, l_pct = 0, 0
        trin_val = 0
        
        if ho_res:
            def c(v): return float(str(v).replace(',','').replace('B','e9').replace('M','e6')) if v else 0
            adv = c(ho_res.get('adv')); dec = c(ho_res.get('dec'))
            adv_v = c(ho_res.get('adv_vol')); dec_v = c(ho_res.get('dec_vol'))
            
            # --- æ·±åº¦ TRIN åˆ†æ (åŸæ ·ä¿ç•™) ---
            if dec > 0 and dec_v > 0:
                trin_val = (adv / dec) / (adv_v / dec_v)
                st.markdown("---")
                st.markdown(f"#### ğŸ” TRIN æŒ‡æ ‡æ·±åº¦åˆ†æ (è¯»æ•°: `{trin_val:.2f}`)")
                
                status_desc = ""
                if trin_val < 0.5: status_desc = "ğŸ”´ **æåº¦å¼ºåŠ¿/ä¸¥é‡è¶…ä¹° (<0.5)** -> è­¦æƒ•é¡¶éƒ¨"
                elif 0.5 <= trin_val <= 0.8: status_desc = "ğŸŸ¢ **å¼ºåŠ¿/ä¹°æ–¹ä¸»å¯¼ (0.5-0.8)** -> å¥åº·ä¸Šæ¶¨"
                elif 0.8 < trin_val <= 1.2: status_desc = "ğŸŸ¢ **ä¸­æ€§/å¹³è¡¡ (0.8-1.2)** -> è§‚æœ›/è·Ÿéš"
                elif 1.2 < trin_val <= 2.0: status_desc = "ğŸŸ¡ **å¼±åŠ¿/å–å‹æ˜¾ç° (1.2-2.0)** -> è°¨æ…å‡ä»“"
                elif trin_val > 2.0: status_desc = "ğŸ”´ **æåº¦ææ…Œ/è¶…å– (>2.0)** -> æŠ„åº•æœºä¼š"
                
                st.write(f"ğŸ‘‰ **çŠ¶æ€åˆ¤å®š:** {status_desc}")
                
                if spx_trend_up:
                    if trin_val < 1.0: st.success("ğŸ“ˆ è¶‹åŠ¿é…åˆ: SPXä¸Šæ¶¨ + TRIN<1.0 (ä¹°æ°”å……è¶³ï¼Œå¥åº·)")
                    elif trin_val > 1.2: st.warning("ğŸ“‰ é‡ä»·èƒŒç¦»: SPXä¸Šæ¶¨ + TRIN>1.2 (ä»·æ ¼æ¶¨ä½†å†…éƒ¨è™šå¼±)")
                else:
                    st.info("âšª [ä¸­æ€§] SPXä¸Šæ¶¨ + TRINæ­£å¸¸")
                
                st.info("ğŸ’¡ å£è¯€: ä½äº0.5è¦å½“å¿ƒ(è§é¡¶)ï¼Œé«˜äº2.0è¦æ¿€åŠ¨(æŠ„åº•)ï¼")
                st.markdown("---")

        # --- æŒ‡æ ‡åˆ¤å®š ---
        indicators = []
        
        # 1. HO
        ho_stat = 0; ho_txt = "æ•°æ®ä¸è¶³"
        if ho_res:
            h = c(ho_res.get('high')); l = c(ho_res.get('low'))
            total = adv + dec + c(ho_res.get('unch', 0))
            if total > 0:
                h_pct = (h/total)*100
                l_pct = (l/total)*100
            
            split = (h_pct > 2.2 and l_pct > 2.2)
            mco_bad = (mco < 0) if mco else (adv < dec)
            if spx_trend_up and split and mco_bad: ho_stat = 2
            elif split: ho_stat = 1
            ho_txt = f"æ–°é«˜:{h_pct:.1f}% | æ–°ä½:{l_pct:.1f}%"
        indicators.append(["Hindenburg Omen", ho_stat, ho_txt, "æ¡ä»¶: 50MAä¸Š & æ–°é«˜ä½>2.2% & MCO<0"])

        # 2. Net Issues
        net_stat = 0; net_issues = adv - dec
        if net_issues < -2000: net_stat = 2
        elif net_issues < -1000: net_stat = 1
        indicators.append(["æŠ›å‹ I: å¹¿åº¦ (Net)", net_stat, f"{net_issues:.0f}", "<-1000 æ˜¾è‘— | <-2000 ææ…Œ"])

        # 3. TRIN
        trin_stat = 0
        if dec > 0 and dec_v > 0:
            if trin_val < 0.5: trin_stat = 2
            elif trin_val > 2.0: trin_stat = 1
        indicators.append(["æŠ›å‹ II: åŠ›åº¦ (TRIN)", trin_stat, f"{trin_val:.2f}", "<0.5(æåº¦è¶…ä¹°) | >2.0(ææ…ŒæŠ„åº•)"])

        # 4. Vol Flow
        vol_stat = 0; vol_txt = "N/A"
        if adv_v > 0:
            ratio = dec_v / adv_v
            if ratio > 9.0: vol_stat = 2
            elif ratio > 4.0: vol_stat = 1
            vol_txt = f"Dn/Up: {ratio:.1f}"
        indicators.append(["æŠ›å‹ III: èµ„é‡‘ (Vol)", vol_stat, vol_txt, "Dn/Up > 4.0 å‡ºé€ƒ | > 9.0 æ´—ç›˜"])

        # 5. NASDAQ
        tv_stat = 0
        if tv_adv and tv_dec:
            ratio = tv_adv / tv_dec
            if ratio < 0.5: tv_stat = 2
            indicators.append(["NASDAQ A/D", tv_stat, f"{ratio:.2f}", "<0.5 ç©ºå¤´ä¸»å¯¼"])
        else: indicators.append(["NASDAQ A/D", 0, "N/A", ""])

        # 6. RSP
        try:
            r = rsp/spy
            curr, ma = r.iloc[-1], r.rolling(50).mean().iloc[-1]
            chg = (curr/r.iloc[-20]-1)*100
            st_rsp = 2 if (curr<ma and chg<-2.0) else (1 if curr<ma else 0)
            indicators.append(["RSP/SPY å¹¿åº¦", st_rsp, f"20æ—¥å˜åŠ¨: {chg:.1f}%", "è·Œç ´50MA & æ€¥è·Œ"])
        except: indicators.append(["RSP/SPY", 0, "Error", ""])
        
        # 7. NYA
        try:
            ok = nya.iloc[-1] > nya.rolling(50).mean().iloc[-1]
            st_nya = 2 if (spx_trend_up and not ok) else 0
            indicators.append(["NYA å‚ä¸åº¦", st_nya, "å¼±" if not ok else "å¼º", "SPXå¼ºä½†NYAå¼±"])
        except: pass

        # 8. å€’æŒ‚
        try:
            spr = tnx.iloc[-1] - irx.iloc[-1]
            indicators.append(["10Y-3M å€’æŒ‚", 2 if spr<0 else 0, f"{spr:.2f}%", "< 0%"])
        except: pass

        # 9-12 å®è§‚
        indicators.append(["Shiller PE", 2 if pe and pe>30 else 0, f"{pe}", ">30 é«˜ä¼°"])
        indicators.append(["å·´è²ç‰¹æŒ‡æ ‡", 2 if buffett and buffett>140 else 0, f"{buffett:.1f}%", ">140%"])
        indicators.append(["Margin Debt", 1 if m_ratio and m_ratio>3.5 else 0, f"GDPæ¯”:{m_ratio:.1f}%", ">3.5%"])
        
        # 13 VIX
        try:
            v = vix.iloc[-1]
            chg = (v/vix.iloc[-15]-1)*100
            st_vix = 2 if (v>25 or chg>40) else 0
            indicators.append(["VIX", st_vix, f"{v:.1f} (+{chg:.0f}%)", ">25 æˆ– é£™å‡"])
        except: pass

        # 14 å¹¿åº¦
        if ma50_pct:
            st_br = 2 if ma50_pct<40 else 0
            indicators.append(["SPX >50MA", st_br, f"{ma50_pct:.1f}%", "<40% å±é™©"])

        # 15 RSI
        try:
            delta = spx_weekly.diff()
            u = delta.clip(lower=0); d = -delta.clip(upper=0)
            rs = u.ewm(alpha=1/14).mean() / d.ewm(alpha=1/14).mean()
            rsi = 100 - 100/(1+rs)
            div = False
            if rsi.iloc[-1] < rsi.iloc[-5] and spx_weekly.iloc[-1] > spx_weekly.iloc[-5]: div = True
            indicators.append(["RSI å‘¨çº¿èƒŒç¦»", 2 if div else 0, f"{rsi.iloc[-1]:.1f}", "ä»·æ¶¨é‡ç¼©"])
        except: pass

        # 16 Support
        try:
            sma20 = spx_weekly.rolling(20).mean().iloc[-1]
            ema21 = spx_weekly.ewm(span=21).mean().iloc[-1]
            status = 2 if spx.iloc[-1] < min(sma20, ema21) else 0
            indicators.append(["ç‰›å¸‚æ”¯æ’‘å¸¦", status, f"ç°ä»·:{spx.iloc[-1]:.0f}", "è·Œç ´ 20SMA/21EMA"])
        except: pass

        # 17-21 å…¶ä»–
        indicators.append(["Fear & Greed", 2 if fg and fg<45 else 0, f"{fg}", "<45"])
        try:
            e12 = spx_weekly.ewm(span=12).mean(); e26 = spx_weekly.ewm(span=26).mean()
            macd = e12 - e26; sig = macd.ewm(span=9).mean()
            dead = (macd.iloc[-2]>sig.iloc[-2]) and (macd.iloc[-1]<sig.iloc[-1]) and (macd.iloc[-1]>0)
            indicators.append(["MACD å‘¨çº¿æ­»å‰", 2 if dead else 0, "æ­»å‰" if dead else "æ­£å¸¸", "é›¶è½´ä¸Šæ–¹æ­»å‰"])
        except: pass
        indicators.append(["Sahm Rule", 2 if sahm and sahm>=0.5 else 0, f"{sahm}%", ">=0.5%"])
        indicators.append(["LEI", 2 if lei_d and lei_d<-4.0 else 0, f"{lei_d}%", "<-4.0%"])
        indicators.append(["PCR", 2 if pcr_avg and pcr_avg<0.8 else 0, f"{pcr_avg}", "<0.8"])
        indicators.append(["NFCI", 2 if nfci and nfci>-0.2 else 0, f"{nfci}", ">-0.2"])
        nymo_st = 2 if nymo and (nymo>60 or nymo<-60) else 0
        indicators.append(["NYMO", nymo_st, f"{nymo}", "æç«¯å€¼ +/-60"])

        return indicators

    def generate_table(self):
        print_h("2. 21å› å­é£é™©ä»ªè¡¨ç›˜ (The 21 Factors)")
        data = self.fetch_and_calculate()
        
        risk_score = sum(1 for d in data if d[1] == 2) + sum(0.5 for d in data if d[1] == 1)
        
        st.markdown(f"<div class='main-header'>ç»¼åˆé£é™©è¯„åˆ†: {risk_score:.1f} / 21.0</div>", unsafe_allow_html=True)
        if risk_score <= 5: st.success("âœ… å¸‚åœºç»“æ„å¥åº·ï¼Œå¯ä¿æŒè§‚å¯Ÿ")
        elif risk_score <= 10: st.warning("ğŸŸ¡ ä¸­æœŸé£é™©ç´¯ç§¯ï¼Œå»ºè®®è°¨æ…")
        else: st.error("ğŸ”´ å´©ç›˜ä¿¡å·å…±æŒ¯ï¼Œå»ºè®®ç«‹å³å‡ä»“")
        
        df_list = []
        for r in data:
            s_txt = "ğŸ”´ å±é™©" if r[1]==2 else ("ğŸŸ¡ è­¦å‘Š" if r[1]==1 else "ğŸŸ¢ å®‰å…¨")
            df_list.append({"ç›‘æµ‹æŒ‡æ ‡": r[0], "çŠ¶æ€": s_txt, "å½“å‰è¯»æ•°": r[2], "åˆ¤æ–­æ ‡å‡†": r[3]})
        
        # ä½¿ç”¨åŸç”Ÿè¡¨æ ¼æ›¿ä»£å›¾ç‰‡ï¼Œæ¸…æ™°ä¸”ä¸åšä½œ
        st.table(pd.DataFrame(df_list))

# ==========================================
# ã€æ¿å—è½®åŠ¨ã€‘
# ==========================================
class SectorRotationEngine:
    def __init__(self):
        self.sectors = {'XLK':'ç§‘æŠ€','XLF':'é‡‘è','XLV':'åŒ»ç–—','XLE':'èƒ½æº','XLY':'å¯é€‰','XLP':'å¿…é€‰','XLI':'å·¥ä¸š','XLC':'é€šè®¯','XLB':'ææ–™','XLRE':'åœ°äº§','SPY':'åŸºå‡†'}
        self.rs_window = 60 
        self.mom_window = 10 

    def run_analysis(self):
        print_h("3. æ¿å—è½®åŠ¨åˆ†æ (Sector Rotation RRG)")
        tickers = list(self.sectors.keys())
        data = get_cached_sector_data(tickers, "2023-01-01")
        if data.empty: return
        
        # ç®€å•è®¡ç®— RRG
        closes = data['Adj Close'] if 'Adj Close' in data else data['Close']
        rs = closes.div(closes['SPY'], axis=0)
        ratio = 100 * (rs / rs.rolling(self.rs_window).mean())
        mom = 100 + ((rs - rs.shift(self.mom_window))/rs.shift(self.mom_window)*100)
        
        # è®¡ç®— 10æ—¥ çˆ†å‘åŠ› (å¯¹åº” output.txt)
        movers = []
        spy_10d = (closes['SPY'].iloc[-1]-closes['SPY'].iloc[-11])/closes['SPY'].iloc[-11]
        for t in self.sectors:
            if t=='SPY': continue
            pct = (closes[t].iloc[-1]-closes[t].iloc[-11])/closes[t].iloc[-11]
            alpha = (pct-spy_10d)*100
            movers.append((self.sectors[t], alpha))
        movers.sort(key=lambda x:x[1], reverse=True)

        # è¾“å‡ºè±¡é™
        res = []
        for t in self.sectors:
            if t=='SPY': continue
            r = ratio[t].iloc[-1]; m = mom[t].iloc[-1]
            q = "ğŸŸ¢ é¢†æ¶¨" if r>100 and m>100 else ("ğŸ”µ æ”¹å–„" if r<100 and m>100 else ("ğŸŸ¡ è½¬å¼±" if r>100 else "ğŸ”´ è½å"))
            res.append({"æ¿å—": self.sectors[t], "RSè¶‹åŠ¿": f"{r:.1f}", "MomåŠ¨é‡": f"{m:.1f}", "è±¡é™": q})
        
        st.dataframe(pd.DataFrame(res), use_container_width=True)
        
        # è¾“å‡º 10æ—¥ èµ„é‡‘æŠ¢ç­¹æ¦œ (è¿˜åŸ output.txt)
        st.write("ğŸš€ **[10æ—¥ èµ„é‡‘æŠ¢ç­¹æ¦œ] (çŸ­æœŸçˆ†å‘åŠ›)**")
        for name, alpha in movers[:3]:
            st.write(f"ğŸ”¥ {name}: è·‘èµ¢å¤§ç›˜ {alpha:.2f}%")

# ==========================================
# ã€SMT èƒŒç¦»ã€‘
# ==========================================
class SMTDivergenceAnalyzer:
    def __init__(self):
        self.tickers = ['^IXIC','^GSPC','QQQ','SPY','NQ=F','ES=F','RSP']
        self.names = {'^IXIC':'çº³æŒ‡','^GSPC':'æ ‡æ™®','QQQ':'QQQ','SPY':'SPY'}

    def run(self):
        print_h("4. SMT èƒŒç¦»åˆ†æ (Pro V3)")
        d = get_cached_smt_data(self.tickers, "6mo")
        if d.empty: return
        c = d['Close'].ffill()
        
        # 1. ç»å…¸ SMT (å¤šçª—å£è¿˜åŸ)
        st.write("**(1) ç»å…¸ SMT åˆ†æ (çº³æŒ‡/æ ‡æ™®/QQQ/SPY)**")
        for p in [3,5,10,20,60]:
            w = c.iloc[-(p+1):]; curr = w.iloc[-1]; h = w.max()
            new_h = [t for t in ['^IXIC','^GSPC','QQQ','SPY'] if curr[t]>=h[t]*0.999]
            if len(new_h)==4: st.write(f"[{p}æ—¥] ğŸ”¥ å¼ºå¤šå¤´å…±æŒ¯ (å…¨éƒ¨åˆ›æ–°é«˜)")
            elif len(new_h)==0: pass 
            else: st.write(f"[{p}æ—¥] âš ï¸ å‡ºç°åˆ†æ­§: {new_h} åˆ›æ–°é«˜")

        # 2. æœŸè´§
        st.write("**(2) è¿›é˜¶ SMT åˆ†æ (æœŸè´§ & å¸‚åœºå¹¿åº¦)**")
        st.info("ğŸ’¡ æœŸè´§(NQ/ES)åŒ…å«å¤œç›˜ï¼Œååº”æ›´çœŸå®ï¼›SPY/RSPæ­ç¤ºåªæœ‰å·¨å¤´åœ¨æ¶¨è¿˜æ˜¯æ™®æ¶¨ã€‚")
        w = c.iloc[-10:]; h = w.max(); cur = w.iloc[-1]
        
        if 'NQ=F' in w and 'ES=F' in w:
            nq_h = cur['NQ=F'] >= h['NQ=F']*0.999
            es_h = cur['ES=F'] >= h['ES=F']*0.999
            if nq_h and not es_h: st.markdown("<div class='highlight'>ğŸ“‰ [10æ—¥ æœŸè´§SMT]: ğŸ”´ çœ‹è·ŒèƒŒç¦» (çº³æŒ‡æ‹‰å‡ï¼Œæ ‡æ™®æ»æ¶¨)</div>", unsafe_allow_html=True)
            elif not nq_h and es_h: st.markdown("<div class='highlight'>ğŸ“‰ [10æ—¥ æœŸè´§SMT]: ğŸ”´ çœ‹è·ŒèƒŒç¦» (æ ‡æ™®è¡¥æ¶¨ï¼Œçº³æŒ‡è¡°ç«­)</div>", unsafe_allow_html=True)
            else: st.success("ğŸ“Š [10æ—¥ æœŸè´§SMT]: ğŸŸ¢ æ­¥è°ƒä¸€è‡´")

        # 3. Vincent ç­–ç•¥ (è¿˜åŸ output.txt)
        print_h("3. å…³é”®ä½ä¸å…¥åœºä¿¡å· (Vincent ç­–ç•¥)")
        spy_curr = cur['SPY']
        ma20 = c['SPY'].rolling(20).mean().iloc[-1]
        dist = (spy_curr - ma20) / ma20 * 100
        
        st.write(f"ğŸ“Œ **æ ‡æ™®ETF(SPY) ä»·æ ¼è¡Œä¸º:**")
        st.write(f"   ç°ä»·: {spy_curr:.2f} (MA20: {ma20:.2f})")
        if spy_curr > ma20 and abs(dist) < 0.6:
            st.success("ğŸ”¥ [ä¿¡å·]: å®Œç¾å›è¸© MA20 (å¤šå¤´åŒºåŸŸ)")
            st.write("ğŸ‘‰ æ“ä½œ: è‹¥ SMT åŒæ—¶å‡ºç°çœ‹æ¶¨èƒŒç¦»ï¼Œåˆ™æ˜¯ç»ä½³ã€åšå¤šã€‘ç‚¹ä½ã€‚")
        elif spy_curr > ma20:
            st.info("ğŸŒŠ [çŠ¶æ€]: è¶‹åŠ¿è¿è¡Œä¸­ (MA20ä¹‹ä¸Š)")
        else:
            st.warning("â„ï¸ [ä¿¡å·]: è·Œç ´ MA20 (ç©ºå¤´åŒºåŸŸ)")

# ==========================================
# ã€ä¸»ç¨‹åºã€‘
# ==========================================
if __name__ == "__main__":
    st.sidebar.title("æ“ä½œå°")
    if st.sidebar.button("ğŸ”„ åˆ·æ–°æŠ¥å‘Š"):
        st.cache_data.clear()
        st.rerun()
        
    st.markdown(f"<div class='main-header'>ğŸš€ ç¾è‚¡å´©ç›˜é¢„è­¦ç³»ç»Ÿ Pro<br><span style='font-size:16px'>ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M')}</span></div>", unsafe_allow_html=True)
    
    app = CrashWarningSystem()
    app.analyze_market_trends_console()
    app.generate_table()
    
    SectorRotationEngine().run_analysis()
    SMTDivergenceAnalyzer().run()
    
    st.balloons()
    st.success("âœ… æ‰€æœ‰åˆ†æä»»åŠ¡æ‰§è¡Œå®Œæ¯•")
    st.stop()
