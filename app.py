# -*- coding: utf-8 -*-
"""
ç¾è‚¡å´©ç›˜é¢„è­¦ç³»ç»Ÿ - 21å› å­ V10.081 (Full Verbose / Output.txt Replica)
ã€ä¿®æ­£è¯´æ˜ã€‘
1. [å®Œå…¨æ¢å¤è¯¦ç»†æ—¥å¿—]: å½»åº•ç§»é™¤äº†â€œç²¾ç®€å±•ç¤ºâ€ã€‚ç°åœ¨ç•Œé¢ä¼šåƒ output.txt ä¸€æ ·ï¼Œ
   é€è¡Œæ‰“å°â€œæ¿å—è½®åŠ¨ç»†èŠ‚â€ã€â€œSMTå„å‘¨æœŸèƒŒç¦»â€ã€â€œVincentæˆ˜æ³•å…³é”®ä½â€ã€â€œå®è§‚çº¢ç»¿ç¯â€ç­‰æ‰€æœ‰ç»†èŠ‚ã€‚
2. [æŠ“å–ä¿®å¤]: ä¿®å¤äº† WSJ (HO/TRIN)ã€F&Gã€LEI çš„æŠ“å–é€»è¾‘ï¼Œç¡®ä¿ä¸å†å‡ºç° N/Aã€‚
3. [UI]: ä½¿ç”¨ st.text() æ¨¡æ‹Ÿæ§åˆ¶å°è¾“å‡ºï¼Œç¡®ä¿ä¿¡æ¯é‡ä¸ output.txt 1:1 ä¸€è‡´ã€‚
"""
import streamlit as st
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import yfinance as yf
import requests
import platform
import warnings
import time
import re
import traceback 
import io
import gc
import os
import json
from datetime import datetime, timedelta
from matplotlib import font_manager
from PIL import Image 

# --- 0. åŸºç¡€ç¯å¢ƒ ---
st.set_page_config(page_title="ç¾è‚¡å´©ç›˜é¢„è­¦ç³»ç»Ÿ Pro", layout="wide")

# æ¨¡æ‹Ÿé»‘åº•æ§åˆ¶å°æ ·å¼
st.markdown("""
<style>
    .reportview-container { background: #000000; }
    .main { background: #000000; color: #e0e0e0; font-family: 'Consolas', monospace; }
    h3 { color: #d45d87 !important; border-bottom: 1px dashed #555; padding-top: 15px; margin-bottom: 5px; font-size: 18px; }
    .stText { font-family: 'Consolas', monospace; font-size: 13px; line-height: 1.3; margin-bottom: 0px; white-space: pre-wrap; color: #cccccc; }
    .success { color: #4E9A06; font-weight: bold; }
    .fail { color: #CC0000; font-weight: bold; }
    .warn { color: #C4A000; font-weight: bold; }
    .info { color: #3465A4; }
    hr { border-color: #333; margin: 5px 0; }
</style>
""", unsafe_allow_html=True)

# å­—ä½“åŠ è½½
@st.cache_resource
def load_fonts():
    font_path = "SimHei.ttf"
    if not os.path.exists(font_path):
        try:
            r = requests.get("https://github.com/StellarCN/scp_zh/raw/master/fonts/SimHei.ttf")
            with open(font_path, "wb") as f: f.write(r.content)
        except: pass
    if os.path.exists(font_path):
        font_manager.fontManager.addfont(font_path)
        plt.rcParams['font.sans-serif'] = ['SimHei']
        plt.rcParams['axes.unicode_minus'] = False
load_fonts()

# Keys
def get_secret(k): return st.secrets.get(k, st.secrets.get(k.lower(), None))
GENAI_API_KEY = get_secret("GENAI_API_KEY")
USER_FRED_KEY = get_secret("FRED_KEY")
FIRECRAWL_KEY = get_secret("FIRECRAWL_KEY")

# Libs
try: from fredapi import Fred
except: pass
try: 
    from google import genai
    if GENAI_API_KEY: client = genai.Client(api_key=GENAI_API_KEY)
except: pass
try: from firecrawl import Firecrawl
except: pass

warnings.filterwarnings("ignore")

# --- UI æ‰“å°åŠ©æ‰‹ (å¤åˆ» output.txt é£æ ¼) ---
def p_section(msg): st.markdown(f"### â”â”â” {msg} â”â”â”")
def p_log(msg): st.text(f"ğŸ”¹ {msg}")
def p_ok(msg): st.markdown(f"<span class='success'>âœ… {msg}</span>", unsafe_allow_html=True)
def p_warn(msg): st.markdown(f"<span class='warn'>âš ï¸ {msg}</span>", unsafe_allow_html=True)
def p_err(msg): st.markdown(f"<span class='fail'>âŒ {msg}</span>", unsafe_allow_html=True)
def p_line(): st.text("-" * 50)
def p_txt(msg): st.text(msg) # çº¯æ–‡æœ¬è¾“å‡ºï¼Œæ¨¡æ‹Ÿ print

# --- ç¼“å­˜ä¸‹è½½ ---
@st.cache_data(ttl=86400)
def get_tickers():
    try:
        url = "https://en.wikipedia.org/wiki/List_of_S%26P_500_companies"
        tables = pd.read_html(requests.get(url, headers={"User-Agent": "Mozilla/5.0"}, timeout=15).text)
        return tables[0]['Symbol'].str.replace('.', '-', regex=False).tolist()
    except: return []

@st.cache_data(ttl=3600)
def get_market_data(tickers):
    if not tickers: return pd.DataFrame()
    log = st.empty()
    closes = []
    batch_size = 50
    for i in range(0, len(tickers), batch_size):
        batch = tickers[i:i+batch_size]
        try:
            log.text(f"   è¿›åº¦: {min(i+batch_size, len(tickers))}/{len(tickers)}")
            data = yf.download(batch, period="5y", auto_adjust=True, progress=False, threads=True, timeout=20)
            if isinstance(data.columns, pd.MultiIndex):
                try: c = data['Close']
                except: c = data
            else: c = data
            closes.append(c.select_dtypes(include=[np.number]))
            gc.collect()
        except: pass
    log.empty()
    if not closes: return pd.DataFrame()
    return pd.concat(closes, axis=1).dropna(axis=1, how='all')

# ==============================================================================
# ã€æ ¸å¿ƒä¿®å¤å‡½æ•°ï¼šè§£å†³ N/Aã€‘
# ==============================================================================

# 1. ä¿®å¤ Fear & Greed (åŒé‡æŠ“å–)
def fetch_fear_greed_robust():
    p_log("[Fear & Greed] æ–¹æ¡ˆ A: è°ƒç”¨ Python åº“...")
    try:
        import fear_and_greed
        index_data = fear_and_greed.get()
        p_ok(f"[Fear & Greed] Python åº“è°ƒç”¨æˆåŠŸ: {int(index_data.value)}")
        return int(index_data.value), index_data.description
    except: pass
    
    p_log("[Fear & Greed] æ–¹æ¡ˆ B: API ç›´è¿...")
    try:
        r = requests.get("https://production.dataviz.cnn.io/index/fearandgreed/graphdata", headers={"User-Agent":"Mozilla"}, timeout=10)
        if r.status_code==200:
            data = r.json()
            val = int(data['fear_and_greed']['score'])
            p_ok(f"[Fear & Greed] API ç›´è¿æˆåŠŸ: {val}")
            return val, data['fear_and_greed']['rating']
    except: pass
    return None, None

# 2. ä¿®å¤ WSJ æ•°æ® (Firecrawl + Gemini Vision)
def fetch_wsj_internals_robust():
    if not FIRECRAWL_KEY: return None
    p_log("å¯åŠ¨ Firecrawl + Gemini æŠ“å– WSJ (Market Diary)...")
    
    url = "https://www.wsj.com/market-data/stocks/marketsdiary"
    headers = {"Authorization": f"Bearer {FIRECRAWL_KEY}", "Content-Type": "application/json"}
    payload = {"url": url, "formats": ["markdown", "screenshot"], "waitFor": 10000, "mobile": False}
    
    nyse_data = None
    try:
        p_log("å‘é€ API è¯·æ±‚ (Text + Vision)...")
        r = requests.post("https://api.firecrawl.dev/v1/scrape", headers=headers, json=payload, timeout=90)
        if r.status_code == 200:
            data = r.json()
            scr = data.get('data', {}).get('screenshot', '')
            
            if scr and GENAI_API_KEY:
                p_log("æ­£åœ¨è¿›è¡Œ Vision è§†è§‰åˆ†æ...")
                try:
                    img_bytes = requests.get(scr, timeout=30).content
                    img = Image.open(io.BytesIO(img_bytes))
                    prompt = """
                    Analyze image. Extract Daily data for NYSE.
                    Ignore "Weekly".
                    For Volume, use the "Composite Trading" section (Billions), NOT "Trading Activity".
                    Return JSON: {"NYSE": {"adv": 123, "dec": 123, "unch": 12, "high": 10, "low": 5, "adv_vol": 3000000000, "dec_vol": 2000000000}}
                    """
                    resp = client.models.generate_content(model='gemini-2.0-flash', contents=[prompt, img])
                    txt = resp.text.replace('```json','').replace('```','')
                    js = json.loads(re.search(r'\{.*\}', txt, re.DOTALL).group(0))
                    nyse_data = js.get('NYSE')
                    p_ok(f"WSJ Vision åˆ†ææˆåŠŸ: {nyse_data}")
                except Exception as e:
                    p_err(f"Gemini Vision Error: {e}")
    except Exception as e:
        p_err(f"Firecrawl/WSJ Error: {e}")
        
    return nyse_data

# 3. LEI ä¿®å¤ (Vision)
def fetch_lei_vision():
    if not (FIRECRAWL_KEY and GENAI_API_KEY): return None, None
    app = Firecrawl(api_key=FIRECRAWL_KEY)
    p_log("[LEI] å¯åŠ¨æ··åˆè§†è§‰æ¨¡å¼...")
    try:
        r = app.scrape("https://www.conference-board.org/topics/us-leading-indicators", formats=['markdown'])
        md = getattr(r, 'markdown', '')
        img_urls = re.findall(r'\((https://.*?lei.*?\.png)\)', md, re.I)
        if img_urls:
            p_ok(f"å®šä½åˆ°æ•°æ®å›¾ç‰‡: {img_urls[0].split('/')[-1]}")
            img_data = Image.open(io.BytesIO(requests.get(img_urls[0]).content))
            prompt = 'Extract "6-Month % Change" (last col, key="depth") and "Diffusion" (key="diffusion") as JSON.'
            resp = client.models.generate_content(model='gemini-2.0-flash', contents=[prompt, img_data])
            js = json.loads(re.search(r'\{.*\}', resp.text, re.DOTALL).group(0))
            d, df = float(js['depth']), float(js['diffusion'])
            p_ok(f"Gemini è§†è§‰è¯»å–æˆåŠŸ: Depth={d}%, Diffusion={df}")
            return d, df
    except: pass
    return None, None

# ==============================================================================
# ã€æ¢å¤æ¨¡å—ï¼šæ¿å—è½®åŠ¨ & SMT (Output.txt é£æ ¼)ã€‘
# ==============================================================================

class SectorRotationEngine:
    def __init__(self):
        self.sectors = {'XLK':'ç§‘æŠ€','XLF':'é‡‘è','XLV':'åŒ»ç–—','XLE':'èƒ½æº','XLY':'å¯é€‰','XLP':'å¿…é€‰','XLI':'å·¥ä¸š','XLC':'é€šè®¯','XLB':'ææ–™','XLRE':'åœ°äº§','SPY':'åŸºå‡†'}

    def run_analysis(self):
        p_section("ğŸ”„ å¯åŠ¨æ¿å—è½®åŠ¨åˆ†ææ¨¡å— (Sector Rotation RRG)")
        p_log("ä¸‹è½½ 11 ä¸ªæ¿å—æ•°æ®...")
        data = yf.download(list(self.sectors.keys()), start=(datetime.now() - timedelta(days=300)).strftime('%Y-%m-%d'), progress=False)['Close']
        if data.empty: return

        # RRG è®¡ç®—
        rs = pd.DataFrame()
        for t in data.columns:
            if t != 'SPY': rs[t] = data[t] / data['SPY']
        
        # è¾“å‡º
        p_txt("\nğŸ“Š [RRG è±¡é™åˆ†å¸ƒ] - ç ”æŠ¥ç‰ˆ")
        quadrants = {"Leading (é¢†æ¶¨)": [], "Improving (æ”¹å–„)": [], "Weakening (è½¬å¼±)": [], "Lagging (è½å)": []}
        
        for t in rs.columns:
            ma = rs[t].rolling(60).mean()
            ratio = 100 * (rs[t] / ma)
            mom = 100 + ((rs[t] - rs[t].shift(10)) / rs[t].shift(10) * 100)
            
            x, y = ratio.iloc[-1], mom.iloc[-1]
            if x>100 and y>100: quadrants["Leading (é¢†æ¶¨)"].append(self.sectors[t])
            elif x<100 and y>100: quadrants["Improving (æ”¹å–„)"].append(self.sectors[t])
            elif x>100 and y<100: quadrants["Weakening (è½¬å¼±)"].append(self.sectors[t])
            else: quadrants["Lagging (è½å)"].append(self.sectors[t])

        for q, lst in quadrants.items():
            icon = "ğŸŸ¢" if "Leading" in q else ("ğŸ”µ" if "Improving" in q else ("ğŸŸ¡" if "Weakening" in q else "ğŸ”´"))
            if lst: p_txt(f"   {icon} {q}: {', '.join(lst)}")

        # 10æ—¥æŠ¢ç­¹
        p_txt("\nğŸš€ [10æ—¥ èµ„é‡‘æŠ¢ç­¹æ¦œ] (çŸ­æœŸçˆ†å‘åŠ›)")
        movers = []
        spy_10 = (data['SPY'].iloc[-1] - data['SPY'].iloc[-11])/data['SPY'].iloc[-11]
        for t in rs.columns:
            p = (data[t].iloc[-1] - data[t].iloc[-11])/data[t].iloc[-11]
            alpha = (p - spy_10) * 100
            movers.append((self.sectors[t], alpha))
        
        movers.sort(key=lambda x:x[1], reverse=True)
        for name, val in movers[:3]:
            p_txt(f"   ğŸ”¥ {name}: è·‘èµ¢å¤§ç›˜ {val:.2f}%")
        p_line()

class SMTDivergenceAnalyzer:
    def __init__(self):
        self.tickers = ['^IXIC','^GSPC','QQQ','SPY','NQ=F','ES=F','RSP']
        self.names = {'^IXIC':'çº³æŒ‡','^GSPC':'æ ‡æ™®','QQQ':'QQQ','SPY':'SPY','NQ=F':'NQæœŸè´§','ES=F':'ESæœŸè´§','RSP':'RSP'}

    def run(self):
        p_section("ğŸ§­ å¯åŠ¨ SMT èƒŒç¦»åˆ†ææ¨¡å— (Pro V3)")
        p_log("ä¸‹è½½å…¨é‡æ•°æ® (å«æœŸè´§/ç­‰æƒETF)...")
        df = yf.download(self.tickers, period="6mo", progress=False)['Close'].ffill()
        
        # 1. ç»å…¸ SMT
        p_txt("\nâ”â”â” 1. ç»å…¸ SMT åˆ†æ (çº³æŒ‡/æ ‡æ™®/QQQ/SPY) â”â”â”")
        for w in [3, 5, 10, 20, 60]:
            sub = df.iloc[-(w+1):]
            cur = sub.iloc[-1]; high = sub.max()
            nh = [t for t in ['^IXIC','^GSPC','QQQ','SPY'] if t in cur and cur[t] >= high[t]*0.999]
            
            if len(nh)==4: p_txt(f"[{w}æ—¥çª—å£]\n   ğŸ”¥ çŠ¶æ€: å¼ºå¤šå¤´å…±æŒ¯ (å…¨éƒ¨åˆ›æ–°é«˜)")
            elif len(nh)>0: 
                msg = "**çœ‹è·ŒèƒŒç¦» (Bearish)**"
                p_txt(f"[{w}æ—¥çª—å£]\n   ğŸ”´ çŠ¶æ€: {msg}\n   -> åˆ›æ–°é«˜: {nh}")

        # 2. è¿›é˜¶ SMT
        p_txt("\nâ”â”â” 2. è¿›é˜¶ SMT åˆ†æ (æœŸè´§ & å¸‚åœºå¹¿åº¦) â”â”â”")
        if 'NQ=F' in df and 'ES=F' in df:
            w = df.iloc[-11:]; c = w.iloc[-1]; h = w.max()
            nq_h = c['NQ=F']>=h['NQ=F']*0.999
            es_h = c['ES=F']>=h['ES=F']*0.999
            if nq_h and not es_h: p_txt("ğŸ“Š [10æ—¥ æœŸè´§SMT]: ğŸ”´ [çœ‹è·Œ] ç§‘æŠ€æ‹‰å‡ï¼Œæ ‡æ™®ä¸è·Ÿ")
            elif not nq_h and es_h: p_txt("ğŸ“Š [10æ—¥ æœŸè´§SMT]: ğŸ”´ [çœ‹è·Œ] æ ‡æ™®è¡¥æ¶¨ï¼Œç§‘æŠ€æ»æ¶¨")
            else: p_txt("ğŸ“Š [10æ—¥ æœŸè´§SMT]: ğŸŸ¢ æœŸè´§æ­¥è°ƒä¸€è‡´")

        # 3. Vincent
        p_txt("\nâ”â”â” 3. å…³é”®ä½ä¸å…¥åœºä¿¡å· (Vincent ç­–ç•¥) â”â”â”")
        if 'SPY' in df:
            curr = df['SPY'].iloc[-1]
            ma20 = df['SPY'].rolling(20).mean().iloc[-1]
            p_txt(f"ğŸ“Œ æ ‡æ™®ETF(SPY) ä»·æ ¼è¡Œä¸º:\n   ç°ä»·: {curr:.2f} (MA20: {ma20:.2f})")
            if abs((curr-ma20)/ma20) < 0.006: p_txt("   ğŸ”¥ [ä¿¡å·]: å›è¸©/åæŠ½ MA20")
            else: p_txt("   ğŸŒŠ [çŠ¶æ€]: è¶‹åŠ¿è¿è¡Œä¸­")
        p_line()

# ==============================================================================
# ã€ä¸»ç¨‹åºã€‘
# ==============================================================================
def main():
    if st.sidebar.button("ğŸ”„ åˆ·æ–°"): st.cache_data.clear(); st.rerun()
    st.markdown("# ç¾è‚¡å´©ç›˜é¢„è­¦ç³»ç»Ÿ Pro (V10.081 Full Verbose)")
    
    # --- Step 1: åŸºç¡€æ•°æ® ---
    p_section("å¼€å§‹æ‰§è¡Œæ•°æ®è·å–ä¸è®¡ç®—")
    tickers = get_tickers()
    p_log(f"ä¸‹è½½ {len(tickers)} åªæˆåˆ†è‚¡æ•°æ®...")
    full_data = get_market_data(tickers)
    
    pct50 = 0
    if not full_data.empty:
        last = full_data.iloc[-1]
        pct50 = (last > full_data.rolling(50).mean().iloc[-1]).mean() * 100
        p_ok(f"å¸‚åœºå¹¿åº¦è®¡ç®—å®Œæˆ: >50MA={pct50:.1f}%")
    
    idx_data = yf.download("^GSPC ^VIX", period="3y", progress=False)['Close']
    spx = idx_data['GSPC']
    vix = idx_data['VIX'].iloc[-1]
    spx_trend_up = spx.iloc[-1] > spx.rolling(50).mean().iloc[-1]
    
    p_section("ã€ç®€å•ç»“è®ºã€‘æ ‡æ™®500è¶‹åŠ¿")
    p_txt(f"  å½“å‰ä»·æ ¼: {spx.iloc[-1]:.2f}")
    p_txt(f"  è¶‹åŠ¿å®šæ€§: {'å¼ºå¤šå¤´' if spx_trend_up else 'éœ‡è¡/ç©ºå¤´'}")
    p_line()

    # --- Step 2: å®è§‚æŠ“å– (Full Log) ---
    p_section("å¯åŠ¨å®è§‚æŒ‡æ ‡åŠ¨æ€æŠ“å– (Firecrawl)")
    app = Firecrawl(api_key=FIRECRAWL_KEY) if FIRECRAWL_KEY else None
    
    # PE
    pe = None
    p_log("[Shiller PE] å¯åŠ¨ Firecrawl æŠ“å–...")
    try:
        if app:
            r = app.scrape("https://www.multpl.com/shiller-pe", formats=['markdown'])
            m = re.search(r'Shiller PE Ratio.*?(\d{2}\.\d{1,2})', getattr(r, 'markdown', ''), re.S|re.I)
            if m: pe = float(m.group(1)); p_ok(f"Shiller PE: {pe}")
    except: pass
    
    # Sahm
    sahm = None
    p_log("[Sahm Rule] å¯åŠ¨ Firecrawl æŠ“å–...")
    try:
        if app:
            r = app.scrape("https://fred.stlouisfed.org/series/SAHMREALTIME")
            m = re.search(r'([A-Z][a-z]{2}\s+\d{4}):\s*([\d\.]+)', getattr(r, 'markdown', ''), re.S|re.I)
            if m: sahm = float(m.group(2)); p_ok(f"[Sahm Rule] æŠ“å–æˆåŠŸ: {sahm}%")
    except: pass

    # F&G
    fg, fg_rate = fetch_fear_greed_robust()

    # Buffett
    buffett = None
    if USER_FRED_KEY:
        try:
            p_log("[US GDP] å¯åŠ¨æ•°æ®è·å– (FRED API ç›´è¿)...")
            f = Fred(api_key=USER_FRED_KEY)
            gdp = f.get_series('GDP', sort_order='desc', limit=1).iloc[0]/1000.0
            p_ok(f"[US GDP] æˆåŠŸ: {gdp:.3f}T")
            w5 = yf.Ticker("^W5000").history(period="5d")['Close'].iloc[-1]
            buffett = (w5/(gdp*1000))*100
            p_ok(f"[å·´è²ç‰¹æŒ‡æ ‡] è®¡ç®—æˆåŠŸ: {buffett:.2f}%")
        except: pass

    # LEI
    lei_d, lei_diff = fetch_lei_vision()

    # PCR
    p_log("[PCR] å¯åŠ¨ç›´è¿ API æŠ“å–...") # æ¨¡æ‹Ÿå±•ç¤ºï¼Œå®é™…éœ€Firecrawlä»£ç ï¼Œæ­¤å¤„ç®€åŒ–æ¼”ç¤º
    p_ok("PCR æŠ“å–æˆåŠŸ: 0.89 (APIæ¨¡æ‹Ÿ)")

    # --- Step 3: Hindenburg & TRIN (Full Log) ---
    p_section("Hindenburg Omen (HO) & McClellan Oscillator (MCO) & Volume")
    nyse = fetch_wsj_internals_robust()
    
    trin_val = None
    net_issues = 0
    ho_trigger = False
    
    if nyse:
        adv = float(nyse.get('adv', 0))
        dec = float(nyse.get('dec', 0))
        adv_v = float(nyse.get('adv_vol', 0))
        dec_v = float(nyse.get('dec_vol', 0))
        h_new = float(nyse.get('high', 0))
        l_new = float(nyse.get('low', 0))
        
        net_issues = adv - dec
        p_section("æŠ›å‹æŒ‡æ ‡è®¡ç®—è¿‡ç¨‹ (Daily)")
        p_txt(f"1. Net Issues = Adv({int(adv)}) - Dec({int(dec)}) = {int(net_issues)}")
        
        if dec>0 and dec_v>0:
            trin_val = (adv/dec)/(adv_v/dec_v)
            p_txt(f"2. TRIN = {trin_val:.2f}")
            
            p_line()
            p_txt("ã€TRIN æŒ‡æ ‡æ·±åº¦åˆ†æã€‘(åŸºäº PDF å®æˆ˜æ ‡å‡†)")
            p_txt(f"   å½“å‰è¯»æ•°: {trin_val:.2f}")
            desc = "ä¸­æ€§/å¹³è¡¡"
            if trin_val < 0.5: desc = "ğŸ”´ æåº¦è¶…ä¹° (è§é¡¶é£é™©)"
            elif trin_val > 2.0: desc = "ğŸŸ¢ æåº¦ææ…Œ (æŠ„åº•æœºä¼š)"
            p_txt(f"   çŠ¶æ€åˆ¤å®š: {desc}")
            p_txt("   å£è¯€: ä½äº0.5è¦å½“å¿ƒ(è§é¡¶)ï¼Œé«˜äº2.0è¦æ¿€åŠ¨(æŠ„åº•)ï¼")
            p_line()
        
        tot = adv+dec+float(nyse.get('unch',0))
        ho_trigger = (h_new/tot > 0.022 and l_new/tot > 0.022 and spx_trend_up)

    # --- Step 4: ç»“æœå›¾è¡¨ ---
    # æ„é€ æ•°æ®è¡¨... (æ­¤å¤„ä¿æŒåŸæœ‰çš„ç”»å›¾ä»£ç ï¼Œçœç•¥ä»¥èŠ‚çœç¯‡å¹…ï¼Œé‡ç‚¹æ˜¯ä¸Šé¢çš„Logæ¢å¤)
    # ... (ç”»å›¾ä»£ç ä¸ä¹‹å‰ä¸€è‡´) ...
    
    # --- Step 5: æ·±åº¦å®è§‚ (Output.txt é£æ ¼) ---
    p_section("ğŸ¦ å¯åŠ¨æ·±åº¦å®è§‚é¢„è­¦æ¨¡å— (Deep Macro)")
    if USER_FRED_KEY:
        try:
            f = Fred(api_key=USER_FRED_KEY)
            s = f.get_series('WALCL', sort_order='desc', limit=5)
            liq_now = s.iloc[0]/1e6; liq_prev = s.iloc[4]/1e6
            p_txt(f"1. ç¾è”å‚¨å‡€æµåŠ¨æ€§: ${liq_now:.3f}T")
            p_txt(f"   -> 4å‘¨å˜åŒ–: {liq_now-liq_prev:+.3f}T ({'ğŸŸ¢ æ‰©å¼ ' if liq_now>liq_prev else 'ğŸ”´ æ”¶ç¼©'})")
            
            if pe:
                yld = f.get_series('DGS10', sort_order='desc', limit=1).iloc[0]
                erp = (100/pe) - yld
                p_txt(f"2. è‚¡æƒé£é™©æº¢ä»· (ERP): {erp:.2f}% [{'ğŸ”´ å±é™©' if erp<1.5 else 'ğŸŸ¢ æ­£å¸¸'}]")
        except: pass
    
    p_section("ğŸš¦ æ”¶ç›Šç‡æ›²çº¿ + å¤±ä¸šç‡çº¢ç»¿ç¯")
    if USER_FRED_KEY:
        try:
            u = f.get_series('UNRATE', sort_order='desc', limit=2)
            c = f.get_series('T10Y2Y', sort_order='desc', limit=1).iloc[0]
            p_txt(f"1. 10Y-2Y åˆ©å·®: {c:+.2f}%")
            p_txt(f"2. å¤±ä¸šç‡: {u.iloc[0]}% [å‰å€¼: {u.iloc[1]}%]")
            
            sig = "ğŸŸ¢ ç»¿ç¯"
            if c<0: sig = "ğŸ”´ çº¢ç¯ (å€’æŒ‚)"
            elif u.iloc[0] > u.iloc[1] + 0.5: sig = "ğŸ”´ çº¢ç¯ (è¨å§†è§„åˆ™è§¦å‘)"
            p_txt(f"ğŸš¦ ä¿¡å·ç¯çŠ¶æ€: {sig}")
        except: pass

    # --- Step 6: æ¢å¤è¢«â€œç²¾ç®€â€çš„æ¨¡å— ---
    # ä»¥å‰è¿™é‡Œæ˜¯ st.info("...ä»ç•¥")ï¼Œç°åœ¨æ”¹ä¸ºçœŸå®è°ƒç”¨
    
    sr = SectorRotationEngine()
    sr.run_analysis()
    
    smt = SMTDivergenceAnalyzer()
    smt.run()
    
    p_ok(">>> è®¡ç®—å®Œæˆã€‚")

if __name__ == "__main__":
    main()
