# -*- coding: utf-8 -*-
"""
ç¾è‚¡å´©ç›˜é¢„è­¦ç³»ç»Ÿ - 21å› å­ V10.065 (Hardcoded Key Edition)
ã€ç»ˆæä¿®æ­£ã€‘
1. å¯†é’¥ç¡¬ç¼–ç ï¼šç›´æ¥å†…ç½®æ‚¨ç”µè„‘ç‰ˆä¸­éªŒè¯é€šè¿‡çš„ API Keyï¼Œç»•è¿‡ Secrets é…ç½®å¯èƒ½å­˜åœ¨çš„é—®é¢˜ã€‚
2. è¯·æ±‚è¿˜åŸï¼šå®Œå…¨æ¢å¤ç”µè„‘ç‰ˆçš„ requests.post ç›´è¿æ–¹å¼æŠ“å– WSJ/PCRï¼Œæ”¾å¼ƒä¸ç¨³å®šåº“å‡½æ•°ã€‚
3. é¡ºåºä¸¥æ ¼ï¼šæ‰§è¡Œé¡ºåº 100% å¯¹é½ output.txtã€‚
4. å†…å­˜é˜²å´©ï¼šä¿ç•™ Batch=20 ä¸‹è½½é™åˆ¶ï¼Œé˜²æ­¢äº‘ç«¯ 1GB å†…å­˜æº¢å‡ºã€‚
"""
import streamlit as st
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import yfinance as yf
import requests
import platform
import warnings
import time
import re
import traceback 
import io
import gc
import json
import os
from datetime import datetime, timedelta
from matplotlib import font_manager
from PIL import Image 

# --- é¡µé¢é…ç½® ---
st.set_page_config(page_title="ç¾è‚¡å´©ç›˜é¢„è­¦ç³»ç»Ÿ Pro", layout="wide")

# --- æ ·å¼ (é»‘åº•æ§åˆ¶å°) ---
st.markdown("""
<style>
    .reportview-container { background: #000000; }
    .main { background: #000000; color: #CCCCCC; font-family: 'Consolas', monospace; }
    h3 { border-bottom: 1px dashed #555; padding-bottom: 10px; color: #d45d87 !important; }
    .stText { font-family: 'Consolas', monospace; white-space: pre-wrap; line-height: 1.5; }
    .success { color: #4E9A06; font-weight: bold; }
    .fail { color: #CC0000; font-weight: bold; }
    .info { color: #3465A4; }
    .highlight { color: #C4A000; font-weight: bold; }
</style>
""", unsafe_allow_html=True)

# --- å­—ä½“å¤„ç† (äº‘ç«¯ç»˜å›¾å¿…é¡») ---
@st.cache_resource
def load_fonts():
    font_path = "SimHei.ttf"
    if not os.path.exists(font_path):
        try:
            r = requests.get("https://github.com/StellarCN/scp_zh/raw/master/fonts/SimHei.ttf")
            with open(font_path, "wb") as f: f.write(r.content)
        except: pass
    if os.path.exists(font_path):
        font_manager.fontManager.addfont(font_path)
        plt.rcParams['font.sans-serif'] = ['SimHei']
        plt.rcParams['axes.unicode_minus'] = False

load_fonts()

# --- æ ¸å¿ƒï¼šç›´æ¥ä½¿ç”¨ç”µè„‘ç‰ˆéªŒè¯è¿‡çš„ Key (ä¸èµ° Secrets) ---
GENAI_API_KEY = "AIzaSyAa66V_LyKhvdIN7MwZvyf4hVPi2M50vsc"
USER_FRED_KEY = "1415a3f3fb1ffc77192884dfca96006c"
FIRECRAWL_KEY = "fc-9073f0b078ff402983472ffd825f6f87"

# --- ä¾èµ–åº“ ---
try: from fredapi import Fred
except: pass
try: from google import genai
except: st.error("âŒ ç¼ºå°‘ google-genai åº“"); st.stop()

client = genai.Client(api_key=GENAI_API_KEY)
warnings.filterwarnings("ignore")

# --- æ¨¡æ‹Ÿæ‰“å° ---
def p_section(msg): st.markdown(f"### â”â”â” {msg} â”â”â”")
def p_log(msg): st.text(f"ğŸ”¹ {msg}")
def p_ok(msg): st.markdown(f"<span class='success'>âœ… {msg}</span>", unsafe_allow_html=True)
def p_err(msg): st.markdown(f"<span class='fail'>âŒ {msg}</span>", unsafe_allow_html=True)
def p_txt(msg): st.text(msg)

# --- ç¼“å­˜å±‚ (Batch=20 é˜²å´©) ---
@st.cache_data(ttl=86400)
def get_cached_tickers():
    try:
        url = "https://en.wikipedia.org/wiki/List_of_S%26P_500_companies"
        tables = pd.read_html(requests.get(url, headers={"User-Agent": "Mozilla/5.0"}, timeout=15).text)
        for t in tables:
            if 'Symbol' in t.columns: return t['Symbol'].str.replace('.', '-', regex=False).tolist()
    except: return []

@st.cache_data(ttl=3600)
def get_cached_sp500_data(tickers):
    if not tickers: return pd.DataFrame()
    log_spot = st.empty()
    closes = []
    batch_size = 20
    total = len(tickers)
    for i in range(0, total, batch_size):
        batch = tickers[i:i+batch_size]
        try:
            log_spot.text(f"   è¿›åº¦: {min(i+batch_size, total)}/{total}")
            data = yf.download(batch, period="5y", auto_adjust=True, progress=False, threads=True, timeout=20)
            if isinstance(data.columns, pd.MultiIndex):
                try: c = data['Close']
                except: c = data
            else: c = data
            closes.append(c.select_dtypes(include=[np.number]))
            gc.collect() 
            time.sleep(0.1)
        except: pass
    log_spot.empty()
    if not closes: return pd.DataFrame()
    try: return pd.concat(closes, axis=1).dropna(axis=1, how='all')
    except: return pd.DataFrame()

@st.cache_data(ttl=3600)
def get_cached_sector_data(tickers, start_date): return yf.download(tickers, start=start_date, progress=False, auto_adjust=False)
@st.cache_data(ttl=3600)
def get_cached_smt_data(tickers, period): return yf.download(tickers, period=period, auto_adjust=False, progress=False)

# --- WebScraper (ä¸¥æ ¼è¿˜åŸç”µè„‘ç‰ˆ requests é€»è¾‘) ---
class WebScraper:
    def __init__(self):
        self.firecrawl_key = FIRECRAWL_KEY
        self.fred_key = USER_FRED_KEY
        self.cached_gdp = None
        self.cached_nasdaq = None

    # é€šç”¨ Firecrawl è¯·æ±‚ (è¿˜åŸ requests.post)
    def _firecrawl_req(self, url, formats=["markdown"], wait=10000):
        headers = {"Authorization": f"Bearer {self.firecrawl_key}", "Content-Type": "application/json"}
        payload = {"url": url, "formats": formats, "waitFor": wait, "mobile": False}
        try:
            # å»¶é•¿ timeout é˜²æ­¢äº‘ç«¯ç½‘ç»œæ…¢
            r = requests.post("https://api.firecrawl.dev/v1/scrape", headers=headers, json=payload, timeout=90)
            if r.status_code == 200: return r.json()['data']
        except: pass
        return None

    def fetch_shiller_pe(self):
        data = self._firecrawl_req("https://www.multpl.com/shiller-pe")
        if data:
            m = re.search(r'Shiller PE Ratio.*?(\d{2}\.\d{1,2})', data.get('markdown', ''), re.S|re.I)
            if m: return float(m.group(1))
        return None

    def fetch_fear_greed(self):
        try:
            r = requests.get("https://production.dataviz.cnn.io/index/fearandgreed/graphdata", headers={"User-Agent":"Mozilla/5.0"}, timeout=10)
            if r.status_code==200: 
                d = r.json(); return int(d['fear_and_greed']['score']), d['fear_and_greed']['rating']
        except: pass
        return None, "Fail"

    def fetch_us_gdp(self):
        if self.cached_gdp: return self.cached_gdp
        try:
            f = Fred(api_key=self.fred_key); s = f.get_series('GDP', sort_order='desc', limit=1)
            self.cached_gdp = s.iloc[0]/1000.0; return self.cached_gdp
        except: return None

    def fetch_buffett_indicator(self):
        gdp = self.fetch_us_gdp()
        if not gdp: return None
        try:
            h = yf.Ticker("^W5000").history(period="5d")
            if not h.empty: return (h['Close'].iloc[-1]/(gdp*1000.0))*100
        except: pass
        return None

    def fetch_margin_debt(self):
        gdp = self.fetch_us_gdp()
        data = self._firecrawl_req("https://www.finra.org/rules-guidance/key-topics/margin-accounts/margin-statistics")
        if data:
            m = re.findall(r'([A-Z][a-z]{2}-\d{2})\s*\|\s*([\d,]+)', data.get('markdown', ''), re.S|re.I)
            if m:
                d = float(m[0][1].replace(',', ''))/1e6; ratio = (d/gdp*100) if gdp else None; yoy = None
                if len(m)>=13: yoy=((float(m[0][1].replace(',',''))-float(m[12][1].replace(',','')))/float(m[12][1].replace(',','')))*100
                return yoy, d, ratio
        return None, None, None

    def fetch_sahm_rule(self):
        data = self._firecrawl_req("https://fred.stlouisfed.org/series/SAHMREALTIME")
        if data:
            m = re.search(r'([A-Z][a-z]{2}\s+\d{4}):\s*([\d\.]+)', data.get('markdown', ''), re.S|re.I)
            if m: return float(m.group(2))
        return None

    def fetch_lei(self):
        # ç”µè„‘ç‰ˆé€»è¾‘ï¼šæ­£åˆ™æ‰¾å›¾ -> Gemini è¯»å›¾
        data = self._firecrawl_req("https://www.conference-board.org/topics/us-leading-indicators")
        if data:
            md = data.get('markdown', '')
            imgs = re.findall(r'\((https://.*?lei.*?\.png)\)', md, re.I)
            if imgs:
                try:
                    img = Image.open(io.BytesIO(requests.get(imgs[0], headers={"User-Agent":"Mozilla/5.0"}).content))
                    ai = client.models.generate_content(model='gemini-2.0-flash', contents=['Extract "6-Month % Change"(depth) and "Diffusion". JSON: {"depth":-2.1,"diffusion":35.0}', img])
                    js = json.loads(re.search(r'\{.*\}', ai.text, re.DOTALL).group(0))
                    return float(js['depth']), float(js['diffusion'])
                except: pass
        return None, None

    def fetch_nyse_internals_robust(self):
        # ç”µè„‘ç‰ˆé€»è¾‘ï¼šrequests.post -> Gemini åˆ†æ
        data = self._firecrawl_req("https://www.wsj.com/market-data/stocks/marketsdiary", formats=["markdown"], wait=12000)
        if data:
            md = data.get('markdown', '')
            prompt = f"Extract NYSE and NASDAQ breadth data. JSON Format. Markdown: {md[:30000]}"
            try:
                ai = client.models.generate_content(model='gemini-2.0-flash', contents=[prompt])
                js = json.loads(re.search(r'\{.*\}', ai.text, re.DOTALL).group(0))
                self.cached_nasdaq = js.get('NASDAQ'); return js.get('NYSE')
            except: pass
        return None

    def fetch_dual_mco(self):
        mco = None; nymo = None
        # 1. MCO
        d1 = self._firecrawl_req("https://www.mcoscillator.com/")
        if d1:
            m = re.search(r'McC\s*OSC\s*\|?\s*([-\d\.]+)', d1.get('markdown', ''), re.I)
            if m: mco = float(m.group(1))
        
        # 2. NYMO Vision (StockCharts)
        d2 = self._firecrawl_req("https://stockcharts.com/h-sc/ui?s=$NYMO", formats=["screenshot"], wait=8000)
        if d2 and d2.get('screenshot'):
            try:
                img = Image.open(io.BytesIO(requests.get(d2['screenshot']).content))
                ai = client.models.generate_content(model='gemini-2.0-flash', contents=['Extract $NYMO value. JSON:{"value":-12.3}', img])
                nymo = float(json.loads(re.search(r'\{.*\}', ai.text, re.DOTALL).group(0))['value'])
            except: pass
        return mco, nymo

    def fetch_tv_breadth_vision(self):
        if self.cached_nasdaq:
            try:
                def c(v): return int(float(str(v).replace(',','').replace('K','000'))) if v else 0
                return c(self.cached_nasdaq.get('adv')), c(self.cached_nasdaq.get('dec'))
            except: pass
        return None, None

    def fetch_pcr_robust(self):
        d = self._firecrawl_req("https://en.macromicro.me/charts/449/us-cboe-options-put-call-ratio", wait=15000)
        if d:
            m = re.findall(r'(\d{1,2}\.\d{2})', d.get('markdown', ''))
            if m: return float(m[0]), float(m[0])
        return None, None

    def fetch_nfci(self):
        try:
            f = Fred(api_key=self.fred_key); s = f.get_series('NFCI', sort_order='desc', limit=1)
            return float(s.iloc[0])
        except: return None

# ==========================================
# ã€æ‰§è¡Œä¸»ç¨‹åº (ä¸¥æ ¼çº¿æ€§æ‰§è¡Œ)ã€‘
# ==========================================
def main():
    if st.sidebar.button("ğŸ”„ åˆ·æ–°"): st.cache_data.clear(); st.rerun()
    st.markdown("# ç¾è‚¡å´©ç›˜é¢„è­¦ç³»ç»Ÿ Pro")
    
    # å˜é‡å…¨åˆå§‹åŒ– (é˜²å´©)
    adv = 0; dec = 0; adv_v = 0; dec_v = 0; net_issues = 0; trin_val = None
    pe = None; sahm = None; fg = None; fg_src = None; buffett = None; gdp = None
    m_yoy = None; m_amt = None; m_ratio = None; lei_d = None; lei_dif = None
    pcr_avg = None; pcr_cur = None; nfci = None
    mco = None; nymo = None; ho_res = None; tv_adv = None; tv_dec = None
    
    scraper = WebScraper()
    colors = {'bg': '#4B535C', 'header': '#3E4953', 'safe': '#2E8B57', 'warn': '#8B0000', 'risk': '#B8860B', 'title': '#FFEE88', 'edge': '#606972'}

    # 1. å¯åŠ¨ & ä¸‹è½½
    p_section("å¼€å§‹æ‰§è¡Œæ•°æ®è·å–ä¸è®¡ç®—")
    p_log("è·å–æ ‡æ™®500æˆåˆ†è‚¡åå•...")
    tickers = get_cached_tickers()
    
    p_log(f"ä¸‹è½½ {len(tickers)} åªæˆåˆ†è‚¡æ•°æ® (5å¹´)...")
    p_txt("â„¹ï¸  ä¿æŒç½‘ç»œé€šç•…ï¼Œæ•°æ®é‡è¾ƒå¤§...")
    full_data = get_cached_sp500_data(tickers)
    
    p_log("æ­£åœ¨æœ¬åœ°è®¡ç®— SMA50 å’Œ SMA20...")
    pct50, pct20, ma50_pct = 0, 0, 0
    if not full_data.empty:
        last = full_data.iloc[-1]
        pct50 = (last > full_data.rolling(50).mean().iloc[-1]).mean() * 100
        pct20 = (last > full_data.rolling(20).mean().iloc[-1]).mean() * 100
        pct200 = (last > full_data.rolling(200).mean().iloc[-1]).mean() * 100
        ma50_pct = pct50
        p_ok(f"å¸‚åœºå¹¿åº¦è®¡ç®—å®Œæˆ: >50MA={pct50:.1f}%, >20MA={pct20:.1f}%, >200MA={pct200:.1f}%")
    
    p_log("è·å–æ ¸å¿ƒæŒ‡æ•°ä¸å®è§‚æ•°æ®...")
    tickers_idx = yf.Tickers("^GSPC ^VIX ^TNX ^IRX RSP SPY ^NYA")
    hist = tickers_idx.history(period="3y", group_by='ticker')
    def get_c(t): return hist[t]['Close'].dropna() if t in hist.columns else pd.Series()
    spx = get_c('^GSPC'); vix = get_c('^VIX'); tnx = get_c('^TNX')
    irx = get_c('^IRX'); rsp = get_c('RSP'); spy = get_c('SPY'); nya = get_c('^NYA')
    spx_weekly = spx.resample('W').last().dropna()
    spx_trend_up = spx.iloc[-1] > spx.rolling(50).mean().iloc[-1] if not spx.empty else False
    st.progress(100)

    # 2. ç»“è®º
    p_section("ã€ç®€å•ç»“è®ºã€‘æ ‡æ™®500è¶‹åŠ¿")
    if not spx.empty:
        curr_px = spx.iloc[-1]
        ma_list = [spx.rolling(n).mean().iloc[-1] for n in [20, 60, 120, 250]]
        trend_desc = "å¼ºå¤šå¤´" if all(curr_px > m for m in ma_list) else "éœ‡è¡"
        p_txt(f"  å½“å‰ä»·æ ¼: {curr_px:.2f}\n  è¶‹åŠ¿å®šæ€§: {trend_desc}")
    st.write("---")

    # 3. å®è§‚æŠ“å–
    p_section("å¯åŠ¨å®è§‚æŒ‡æ ‡åŠ¨æ€æŠ“å– (Firecrawl)")
    p_log("[Shiller PE] å¯åŠ¨ Firecrawl æŠ“å–...")
    pe = scraper.fetch_shiller_pe()
    if pe: p_ok(f"AI è¯†åˆ«æˆåŠŸ! Shiller PE: {pe}")

    p_log("[Sahm Rule] å¯åŠ¨ Firecrawl æŠ“å–...")
    sahm = scraper.fetch_sahm_rule()

    p_log("[Fear & Greed] è°ƒç”¨...")
    fg, fg_src = scraper.fetch_fear_greed()
    if fg: p_ok(f"F&G Index: {fg}")

    p_log("[Buffett] è®¡ç®—...")
    buffett = scraper.fetch_buffett_indicator()

    p_section("[US GDP] å¯åŠ¨æ•°æ®è·å–...")
    gdp = scraper.fetch_us_gdp()

    p_section("[Margin Debt] å¯åŠ¨ Firecrawl...")
    m_yoy, m_amt, m_ratio = scraper.fetch_margin_debt()

    p_section("[LEI 3Ds] å¯åŠ¨æ··åˆè§†è§‰æ¨¡å¼...")
    lei_d, lei_dif = scraper.fetch_lei()

    p_section("[PCR] å¯åŠ¨ç›´è¿ API æŠ“å–...")
    pcr_avg, pcr_cur = scraper.fetch_pcr_robust()

    p_section("èŠåŠ å“¥é‡‘èçŠ¶å†µæŒ‡æ•° (NFCI)")
    nfci = scraper.fetch_nfci()
    if nfci: p_ok(f"NFCI: {nfci}")

    # 4. å†…éƒ¨ç»“æ„
    p_section("Hindenburg Omen (HO) & McClellan Oscillator (MCO) & Volume")
    p_log("[MCO] å¯åŠ¨å®˜æ–¹æº + NYMO...")
    mco, nymo = scraper.fetch_dual_mco()
    
    p_log("å¯åŠ¨ WSJ æŠ“å–...")
    ho_res = scraper.fetch_nyse_internals_robust()
    
    if ho_res:
        def c(v): return float(str(v).replace(',','').replace('B','e9').replace('M','e6')) if v else 0
        adv = c(ho_res.get('adv')); dec = c(ho_res.get('dec'))
        adv_v = c(ho_res.get('adv_vol')); dec_v = c(ho_res.get('dec_vol'))
        net_issues = adv - dec
        
        p_section("æŠ›å‹æŒ‡æ ‡è®¡ç®—è¿‡ç¨‹ (Daily)")
        p_txt(f"1. Net Issues = Adv({adv:.0f}) - Dec({dec:.0f}) = {net_issues:.0f}")
        
        if dec > 0 and dec_v > 0:
            trin_val = (adv/dec) / (adv_v/dec_v)
            p_txt(f"2. TRIN = {trin_val:.2f}")
            st.write("---")
            st.markdown(f"**ã€TRIN æŒ‡æ ‡æ·±åº¦åˆ†æã€‘** (å½“å‰: `{trin_val:.2f}`)")
            desc = "ğŸŸ¢ ä¸­æ€§/å¹³è¡¡"
            if trin_val < 0.5: desc = "ğŸ”´ æåº¦è¶…ä¹° (<0.5) -> è­¦æƒ•é¡¶éƒ¨"
            elif trin_val > 2.0: desc = "ğŸ”´ æåº¦ææ…Œ (>2.0) -> æŠ„åº•æœºä¼š"
            p_txt(f"   çŠ¶æ€åˆ¤å®š: {desc}")
            p_txt("   å£è¯€: ä½äº0.5è¦å½“å¿ƒ(è§é¡¶)ï¼Œé«˜äº2.0è¦æ¿€åŠ¨(æŠ„åº•)ï¼")
            st.write("---")
        if adv_v > 0: p_txt(f"3. Vol Ratio = {dec_v/adv_v:.2f}")

    tv_adv, tv_dec = scraper.fetch_tv_breadth_vision()
    if tv_adv:
        p_section("ã€é‡ç‚¹æ•°æ®ã€‘NASDAQ å¹¿åº¦")
        p_txt(f"  ğŸ“ˆ ä¸Šæ¶¨: {tv_adv} | ğŸ“‰ ä¸‹è·Œ: {tv_dec}")

    p_section("ã€ç®€å•ç»“è®ºã€‘NYMO å¹¿åº¦")
    p_txt(f"  å½“å‰è¯»æ•°: {nymo}")
    st.write("---")

    # 5. ç”Ÿæˆå›¾è¡¨ (Matplotlib åŸå›¾)
    indicators = []
    ho_stat = 0; ho_txt = "æ•°æ®ä¸è¶³"
    if ho_res:
        h = c(ho_res.get('high')); l = c(ho_res.get('low'))
        tot = adv+dec+c(ho_res.get('unch',0))
        h_pct = (h/tot)*100 if tot else 0; l_pct = (l/tot)*100 if tot else 0
        split = (h_pct>2.2 and l_pct>2.2)
        mco_bad = (mco < 0) if mco else (adv<dec)
        if spx_trend_up and split and mco_bad: ho_stat=2
        elif split: ho_stat=1
        ho_txt = f"æ–°é«˜:{h_pct:.1f}% | æ–°ä½:{l_pct:.1f}%"
    indicators.append(["Hindenburg Omen (å‡¶å…†)", ho_stat, ho_txt, "æ¡ä»¶: 50MAä¸Š & æ–°é«˜ä½>2.2% & MCO<0"])
    
    net_stat = 0; 
    if net_issues < -2000: net_stat = 2
    elif net_issues < -1000: net_stat = 1
    indicators.append(["æŠ›å‹ç›‘æµ‹ I: å¹¿åº¦", net_stat, f"{net_issues:.0f}", "<-1000 æ˜¾è‘— | <-2000 ææ…Œ"])
    
    trin_stat = 0
    if trin_val and trin_val < 0.5: trin_stat = 2
    elif trin_val and trin_val > 2.0: trin_stat = 1
    indicators.append(["æŠ›å‹ç›‘æµ‹ II: åŠ›åº¦", trin_stat, f"{trin_val:.2f}" if trin_val else "N/A", "<0.5(æåº¦è¶…ä¹°) | >2.0(ææ…ŒæŠ„åº•)"])
    
    vol_stat = 0; vol_txt = "N/A"
    if adv_v > 0:
        ratio = dec_v / adv_v
        if ratio > 9.0: vol_stat = 2
        elif ratio > 4.0: vol_stat = 1
        vol_txt = f"Dn/Up: {ratio:.1f}"
    indicators.append(["æŠ›å‹ç›‘æµ‹ III: èµ„é‡‘", vol_stat, vol_txt, "Dn/Up > 4.0 å‡ºé€ƒ | > 9.0 æ´—ç›˜"])

    indicators.append(["NASDAQ å¹¿åº¦", 0, f"{tv_adv}/{tv_dec}" if tv_adv else "N/A", "<0.5 ç©ºå¤´ä¸»å¯¼"])
    indicators.append(["RSP/SPY å¹¿åº¦", 0, "N/A", "è·Œç ´50MA & æ€¥è·Œ"])
    indicators.append(["å…¨å¸‚åœºå‚ä¸åº¦", 0, "N/A", "SPXå¼ºä½†NYAå¼±"])
    indicators.append(["æ”¶ç›Šç‡å€’æŒ‚", 0, "N/A", "< 0%"])
    indicators.append(["Shiller PE", 2 if pe and pe>30 else 0, f"{pe}", ">30 é«˜ä¼°"])
    indicators.append(["å·´è²ç‰¹æŒ‡æ ‡", 2 if buffett and buffett>140 else 0, f"{buffett:.1f}%", ">140%"])
    indicators.append(["Margin Debt", 1 if m_ratio and m_ratio>3.5 else 0, f"GDP%:{m_ratio:.1f}%" if m_ratio else "N/A", ">3.5%"])
    indicators.append(["VIX", 0, f"{vix.iloc[-1]:.1f}" if not vix.empty else "N/A", ">25"])
    if ma50_pct: indicators.append(["SPX >50MA", 2 if ma50_pct<40 else 0, f"{ma50_pct:.1f}%", "<40% å±é™©"])
    indicators.append(["RSI", 0, "N/A", "èƒŒç¦»"])
    indicators.append(["ç‰›å¸‚æ”¯æ’‘å¸¦", 0, "N/A", "è·Œç ´"])
    indicators.append(["Fear & Greed", 2 if fg and fg<45 else 0, f"{fg}", "<45"])
    indicators.append(["MACD", 0, "N/A", "æ­»å‰"])
    indicators.append(["Sahm Rule", 2 if sahm and sahm>=0.5 else 0, f"{sahm}%", ">=0.5%"])
    indicators.append(["LEI", 2 if lei_d and lei_d<-4.0 else 0, f"{lei_d}%", "<-4.0%"])
    indicators.append(["PCR", 2 if pcr_avg and pcr_avg<0.8 else 0, f"{pcr_avg}", "<0.8"])
    indicators.append(["NFCI", 2 if nfci and nfci>-0.2 else 0, f"{nfci}", ">-0.2"])
    indicators.append(["NYMO", 2 if nymo and abs(nymo)>60 else 0, f"{nymo}", "+/-60"])

    # ç»˜å›¾
    risk_score = sum(1 for d in indicators if d[1] == 2) + sum(0.5 for d in indicators if d[1] == 1)
    fig = plt.figure(figsize=(15, len(indicators)*0.9), facecolor=colors['bg'])
    ax = fig.add_subplot(111); ax.axis('off')
    ax.text(0.5, 0.98, f"ç¾è‚¡å´©ç›˜é¢„è­¦ç³»ç»Ÿ - 21å› å­ V10 (Score: {risk_score:.1f}/21)", ha='center', va='center', fontsize=20, color=colors['title'], weight='bold')
    
    table_data = []
    cell_colors = []
    for d in indicators:
        name, stat, val, desc = d
        s_txt = "ã€!ã€‘è§¦å‘" if stat==2 else ("ã€!ã€‘é¢„è­¦" if stat==1 else "ã€âˆšã€‘å®‰å…¨")
        if str(val) == "N/A" or str(val)=="None": s_txt = "ã€?ã€‘ç¼ºå¤±"
        table_data.append([name, s_txt, val, desc])
        c = colors['safe']
        if stat == 2: c = colors['warn']
        elif stat == 1: c = colors['risk']
        cell_colors.append([c, c, c, c])
        
    t = ax.table(cellText=table_data, colLabels=['ç›‘æµ‹æŒ‡æ ‡', 'çŠ¶æ€è¯„çº§', 'å½“å‰è¯»æ•°', 'åˆ¤æ–­é€»è¾‘'], loc='center', cellLoc='center', colWidths=[0.25, 0.15, 0.25, 0.35])
    t.scale(1, 2.5); t.auto_set_font_size(False); t.set_fontsize(14)
    for i, key in enumerate(t.get_celld().keys()):
        cell = t.get_celld()[key]; row, col = key
        cell.set_edgecolor(colors['edge']); cell.set_linewidth(1)
        if row == 0:
            cell.set_facecolor(colors['header']); cell.set_text_props(color='white', weight='bold')
        else:
            cell.set_facecolor(cell_colors[row-1][col]); cell.set_text_props(color='white', weight='bold')
    st.pyplot(fig)

    # 6. FRED
    p_section("ğŸš¦ æ”¶ç›Šç‡æ›²çº¿ + å¤±ä¸šç‡çº¢ç»¿ç¯")
    if USER_FRED_KEY:
        try:
            f = Fred(api_key=USER_FRED_KEY)
            c = f.get_series('T10Y2Y', sort_order='desc', limit=1).iloc[0]
            u = f.get_series('UNRATE', sort_order='desc', limit=1).iloc[0]
            p_txt(f"1. 10Y-2Y åˆ©å·®: {c:+.2f}%")
            p_txt(f"2. å¤±ä¸šç‡: {u}%")
            st.write("--------------------------------------------------")
            sig = "ğŸŸ¢ è¶…çº§ç»¿ç¯ (æœ€ä½³ä¹°ç‚¹)" if c > 0 else "ğŸ”´ çº¢ç¯"
            p_txt(f"ğŸš¦ ä¿¡å·ç¯çŠ¶æ€: {sig}")
        except: pass
    st.write("==================================================")

    # 7. Deep Macro
    p_section("ğŸ¦ å¯åŠ¨æ·±åº¦å®è§‚é¢„è­¦æ¨¡å— (Deep Macro)")
    if USER_FRED_KEY:
        try:
            f = Fred(api_key=USER_FRED_KEY)
            start = datetime.now() - timedelta(weeks=5)
            liq = (f.get_series('WALCL', observation_start=start).iloc[-1]/1e6) - \
                  (f.get_series('WTREGEN', observation_start=start).iloc[-1]/1e3) - \
                  (f.get_series('RRPONTSYD', observation_start=start).iloc[-1]/1e3)
            p_txt(f"1. ç¾è”å‚¨å‡€æµåŠ¨æ€§: ${liq:.3f}T")
            
            pe = scraper.fetch_shiller_pe() or 35.0
            erp = (1.0/pe*100) - f.get_series('DGS10', sort_order='desc', limit=1).iloc[-1]
            p_txt(f"2. è‚¡æƒé£é™©æº¢ä»· (ERP): {erp:.2f}%")
            
            try:
                d = yf.download(['SPY','RSP'], period="3mo", progress=False)['Close']
                chg = ((d['RSP'].iloc[-1]/d['SPY'].iloc[-1]) - (d['RSP'].iloc[-20]/d['SPY'].iloc[-20])) / (d['RSP'].iloc[-20]/d['SPY'].iloc[-20]) * 100
                p_txt(f"3. RSP/SPY ç›¸å¯¹å¼ºåº¦: {chg:+.2f}%")
            except: pass
        except: pass
    st.write("==================================================")

    # 8. Sector Rotation
    p_section("ğŸ”„ å¯åŠ¨æ¿å—è½®åŠ¨åˆ†ææ¨¡å—")
    secs = {'XLK':'ç§‘æŠ€','XLF':'é‡‘è','XLV':'åŒ»ç–—','XLE':'èƒ½æº','XLY':'å¯é€‰','XLP':'å¿…é€‰','XLI':'å·¥ä¸š','XLC':'é€šè®¯','XLB':'ææ–™','XLRE':'åœ°äº§','SPY':'åŸºå‡†'}
    d = get_cached_sector_data(list(secs.keys()), "2023-01-01")
    if not d.empty:
        c = d['Adj Close'] if 'Adj Close' in d else d['Close']
        rs = c.div(c['SPY'], axis=0); r = 100*(rs/rs.rolling(60).mean()); m = 100+((rs-rs.shift(10))/rs.shift(10)*100)
        
        p_txt("ğŸ“Š [RRG è±¡é™åˆ†å¸ƒ]")
        for q in ["Leading (é¢†æ¶¨)", "Weakening (è½¬å¼±)", "Lagging (è½å)", "Improving (æ”¹å–„)"]:
            l = []
            for t in secs:
                if t=='SPY': continue
                rv = r[t].iloc[-1]; mv = m[t].iloc[-1]
                if (rv>100 and mv>100 and "Leading" in q) or (rv<100 and mv<100 and "Lagging" in q) or (rv>100 and mv<100 and "Weakening" in q) or (rv<100 and mv>100 and "Improving" in q):
                    l.append(secs[t])
            if l: p_txt(f"   {q}: {', '.join(l)}")
        
        p_txt("ğŸš€ [10æ—¥ èµ„é‡‘æŠ¢ç­¹æ¦œ]")
        spy10 = (c['SPY'].iloc[-1]-c['SPY'].iloc[-11])/c['SPY'].iloc[-11]
        mov = []
        for t in secs:
            if t=='SPY': continue
            p = (c[t].iloc[-1]-c[t].iloc[-11])/c[t].iloc[-11]
            mov.append((secs[t], (p-spy10)*100))
        mov.sort(key=lambda x:x[1], reverse=True)
        for n, v in mov[:3]: p_txt(f"   ğŸ”¥ {n}: è·‘èµ¢å¤§ç›˜ {v:.2f}%")
    st.write("==================================================")

    # 9. SMT Analysis
    p_section("ğŸ§­ å¯åŠ¨ SMT èƒŒç¦»åˆ†ææ¨¡å— (Pro V3)")
    ts = ['^IXIC','^GSPC','QQQ','SPY','NQ=F','ES=F','RSP']
    d = get_cached_smt_data(ts, "6mo"); 
    if not d.empty:
        c = d['Close'].ffill()
        p_section("1. ç»å…¸ SMT åˆ†æ")
        for p in [3,5,10,20,60]:
            w = c.iloc[-(p+1):]; cur = w.iloc[-1]; h = w.max()
            nh = [t for t in ['^IXIC','^GSPC','QQQ','SPY'] if cur[t]>=h[t]*0.999]
            if len(nh)==4: p_txt(f"[{p}æ—¥çª—å£] ğŸ”¥ çŠ¶æ€: å¼ºå¤šå¤´å…±æŒ¯")
            elif len(nh)>0: p_txt(f"[{p}æ—¥çª—å£] âš ï¸ åˆ†æ­§: {nh} åˆ›æ–°é«˜")
        st.write("--------------------------------------------------")
        
        p_section("2. è¿›é˜¶ SMT åˆ†æ")
        w = c.iloc[-10:]; h = w.max(); cur = w.iloc[-1]
        if 'NQ=F' in w:
            nq_h = cur['NQ=F']>=h['NQ=F']*0.999; es_h = cur['ES=F']>=h['ES=F']*0.999
            if nq_h and not es_h: p_txt("ğŸ“Š [10æ—¥ æœŸè´§SMT]: ğŸ”´ [çœ‹è·Œ] çº³æŒ‡æ‹‰å‡ï¼Œæ ‡æ™®æ»æ¶¨")
            elif not nq_h and es_h: p_txt("ğŸ“Š [10æ—¥ æœŸè´§SMT]: ğŸ”´ [çœ‹è·Œ] æ ‡æ™®è¡¥æ¶¨ï¼Œç§‘æŠ€æ»æ¶¨")
            else: p_txt("ğŸ“Š [10æ—¥ æœŸè´§SMT]: ğŸŸ¢ æ­¥è°ƒä¸€è‡´")
        st.write("--------------------------------------------------")
        
        p_section("3. å…³é”®ä½ä¸å…¥åœºä¿¡å·")
        s = c['SPY']; ma20 = s.rolling(20).mean().iloc[-1]; now = s.iloc[-1]
        p_txt(f"ğŸ“Œ æ ‡æ™®ETF(SPY) ä»·æ ¼è¡Œä¸º:")
        p_txt(f"   ç°ä»·: {now:.2f} (MA20: {ma20:.2f})")
        if now > ma20: p_txt("   ğŸŒŠ [çŠ¶æ€]: è¶‹åŠ¿è¿è¡Œä¸­ (MA20ä¹‹ä¸Š)")
        else: p_txt("   â„ï¸ [ä¿¡å·]: è·Œç ´ MA20")
    st.write("==================================================")

    st.write("\n")
    p_ok(">>> è®¡ç®—å®Œæˆã€‚")
    st.stop()

if __name__ == "__main__":
    main()
