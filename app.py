# -*- coding: utf-8 -*-
"""
ç¾è‚¡å´©ç›˜é¢„è­¦ç³»ç»Ÿ - 21å› å­ V10.102 (Logic Restoration)
ã€ä¿®å¤è¯´æ˜ã€‘
1. [å…³é”®ç§»æ¤]ï¼šä»ç”µè„‘ç‰ˆ (21 factor 2026-01-12A.py) 100% ç§»æ¤ McClellan Oscillator (MCO) å’Œ NYMO é€»è¾‘ã€‚
2. [æ ¼å¼æ¸…æ´—]ï¼šå½»åº•ç§»é™¤æ‰€æœ‰ URL å­—ç¬¦ä¸²ä¸­çš„ Markdown æ ‡è®°ï¼ˆ[ ] ( )ï¼‰ï¼Œè§£å†³ 'Invalid URL' æŠ¥é”™ã€‚
3. é“å¾‹æ‰§è¡Œï¼šé™¤æ˜ç¡®è¦æ±‚ä¿®å¤çš„æŒ‡æ ‡å¤–ï¼Œå…¶ä½™ä»£ç ç»“æ„å®Œå…¨ä¸åŠ¨ã€‚
"""
import streamlit as st
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import yfinance as yf
import requests
import platform
import warnings
import time
import re
import traceback 
import io
import gc
import os
import json
from datetime import datetime, timedelta
from matplotlib import font_manager
from PIL import Image 

# --- 0. åŸºç¡€ç¯å¢ƒ ---
st.set_page_config(page_title="ç¾è‚¡å´©ç›˜é¢„è­¦ç³»ç»Ÿ Pro", layout="wide")

# æ¨¡æ‹Ÿé»‘åº•æ§åˆ¶å°
st.markdown("""
<style>
    .reportview-container { background: #000000; }
    .main { background: #000000; color: #cccccc; font-family: 'Consolas', 'Courier New', monospace; }
    h3 { color: #d45d87 !important; border-bottom: 1px dashed #555; padding-top: 15px; margin-bottom: 5px; font-size: 18px; }
    .stText { 
        font-family: 'Consolas', 'Courier New', monospace !important; 
        font-size: 13px; 
        line-height: 1.4; 
        color: #cccccc; 
        white-space: pre-wrap; 
        margin-bottom: 0px;
    }
    .success { color: #4E9A06; font-weight: bold; }
    .fail { color: #CC0000; font-weight: bold; }
    .warn { color: #C4A000; font-weight: bold; }
    .info { color: #3465A4; }
    hr { border-color: #333; margin: 5px 0; }
</style>
""", unsafe_allow_html=True)

# å­—ä½“åŠ è½½
@st.cache_resource
def load_fonts():
    font_path = "SimHei.ttf"
    if not os.path.exists(font_path):
        try:
            r = requests.get("https://github.com/StellarCN/scp_zh/raw/master/fonts/SimHei.ttf")
            with open(font_path, "wb") as f: f.write(r.content)
        except: pass
    if os.path.exists(font_path):
        font_manager.fontManager.addfont(font_path)
        plt.rcParams['font.sans-serif'] = ['SimHei']
        plt.rcParams['axes.unicode_minus'] = False
load_fonts()

# Keys
def get_secret(k): return st.secrets.get(k, st.secrets.get(k.lower(), None))
GENAI_API_KEY = get_secret("GENAI_API_KEY")
USER_FRED_KEY = get_secret("FRED_KEY")
FIRECRAWL_KEY = get_secret("FIRECRAWL_KEY")

# Libs
try: from fredapi import Fred
except: pass
try: 
    from google import genai
    if GENAI_API_KEY: client = genai.Client(api_key=GENAI_API_KEY)
except: pass
try: from firecrawl import Firecrawl
except: pass

warnings.filterwarnings("ignore")

# --- UI åŠ©æ‰‹ ---
def p_section(msg): st.markdown(f"### â”â”â” {msg} â”â”â”")
def p_log(msg): st.text(f"ğŸ”¹ {msg}")
def p_ok(msg): st.markdown(f"<span class='success'>âœ… {msg}</span>", unsafe_allow_html=True)
def p_warn(msg): st.markdown(f"<span class='warn'>âš ï¸ {msg}</span>", unsafe_allow_html=True)
def p_err(msg): st.markdown(f"<span class='fail'>âŒ {msg}</span>", unsafe_allow_html=True)
def p_txt(msg): st.text(msg) 
def p_sep(): st.text("-" * 60)

# ==============================================================================
# ã€çˆ¬è™«å±‚ã€‘WebScraper (100% ç§»æ¤ç”µè„‘ç‰ˆæˆç†Ÿé€»è¾‘)
# ==============================================================================
class WebScraper:
    def __init__(self):
        self.firecrawl_key = FIRECRAWL_KEY
        self.app = Firecrawl(api_key=self.firecrawl_key) if self.firecrawl_key else None
        self.fred_key = USER_FRED_KEY

    def fetch_shiller_pe(self):
        p_log("[Shiller PE] å¯åŠ¨ Firecrawl æŠ“å– (Multpl)...")
        try:
            if self.app:
                r = self.app.scrape("https://www.multpl.com/shiller-pe", formats=['markdown'])
                m = re.search(r'Shiller PE Ratio.*?(\d{2}\.\d{1,2})', getattr(r, 'markdown', ''), re.S|re.I)
                if m: 
                    v = float(m.group(1))
                    p_ok("AI è¯†åˆ«æˆåŠŸ!")
                    p_txt(f"Shiller PE: {v}")
                    return v
        except: pass
        return None

    def fetch_fear_greed(self):
        p_log("[Fear & Greed] æ–¹æ¡ˆ A: è°ƒç”¨ Python åº“ (fear_and_greed)...")
        try:
            import fear_and_greed
            idx = fear_and_greed.get()
            val = int(idx.value)
            p_ok(f"[Fear & Greed] Python åº“è°ƒç”¨æˆåŠŸ: {val} ({idx.description})")
            return val, idx.description
        except: pass
        p_log("[Fear & Greed] æ–¹æ¡ˆ B: å¯åŠ¨ API ç›´è¿...")
        try:
            url = "https://production.dataviz.cnn.io/index/fearandgreed/graphdata"
            headers = {"User-Agent": "Mozilla/5.0", "Referer": "https://www.cnn.com/"}
            r = requests.get(url, headers=headers, timeout=10)
            if r.status_code==200:
                d = r.json()
                val = int(d['fear_and_greed']['score'])
                p_ok(f"[Fear & Greed] API å…œåº•æˆåŠŸ: {val}")
                return val, d['fear_and_greed']['rating']
        except: pass
        return None, "ç¼ºå¤±"

    def fetch_sahm_rule(self):
        p_log("[Sahm Rule] å¯åŠ¨ Firecrawl æŠ“å– (FRED)...")
        try:
            if self.app:
                r = self.app.scrape("https://fred.stlouisfed.org/series/SAHMREALTIME", formats=['markdown'])
                m = re.search(r'([A-Z][a-z]{2}\s+\d{4}):\s*([\d\.]+)', getattr(r, 'markdown', ''), re.S|re.I)
                if m: 
                    v = float(m.group(2))
                    p_ok(f"[Sahm Rule] æŠ“å–æˆåŠŸ: {v}%")
                    return v
        except: pass
        return None

    def fetch_lei(self):
        p_section("[LEI 3Ds] å¯åŠ¨æ··åˆè§†è§‰æ¨¡å¼ (Old Code Logic)...")
        if not (self.app and GENAI_API_KEY): return None, None
        try:
            p_log("æ­£åœ¨è§£æé¡µé¢ç»“æ„ (å¯»æ‰¾ Summary Table å›¾ç‰‡)...")
            response = self.app.scrape("https://www.conference-board.org/topics/us-leading-indicators", formats=['markdown'])
            md = getattr(response, 'markdown', '')
            img_url = None
            if md:
                anchor_idx = md.find("Summary Table")
                if anchor_idx == -1: anchor_idx = md.find("Composite Economic Indexes")
                if anchor_idx != -1:
                    snippet = md[anchor_idx : anchor_idx + 1500]
                    img_match = re.search(r'\((https://.*?lei.*?\.png)\)', snippet, re.I)
                    if img_match:
                        img_url = img_match.group(1)
                        p_ok(f"å®šä½åˆ°æ•°æ®å›¾ç‰‡: {img_url.split('/')[-1]}")
                if not img_url:
                    all_imgs = re.findall(r'\((https://.*?lei.*?\.png)\)', md, re.I)
                    if all_imgs: img_url = all_imgs[0]
            if img_url:
                p_log("ä¸‹è½½å›¾ç‰‡å¹¶è¿›è¡Œ AI åˆ†æ...")
                img_resp = requests.get(img_url, headers={"User-Agent": "Mozilla/5.0"}, timeout=10)
                if img_resp.status_code == 200:
                    img_data = Image.open(io.BytesIO(img_resp.content))
                    prompt = """Analyze this LEI Summary Table image. Extract: 1. "6-Month % Change" (Key: "depth") 2. "Diffusion" (Key: "diffusion"). Return ONLY JSON."""
                    ai_resp = client.models.generate_content(model='gemini-2.0-flash', contents=[prompt, img_data])
                    if ai_resp and ai_resp.text:
                        json_match = re.search(r'\{.*\}', ai_resp.text, re.DOTALL)
                        if json_match:
                            js = json.loads(json_match.group(0))
                            p_ok(f"Gemini è§†è§‰è¯»å–æˆåŠŸ: Depth={js.get('depth')}%, Diffusion={js.get('diffusion')}")
                            return float(js.get('depth')), float(js.get('diffusion'))
        except Exception as e: p_err(f"LEI æµç¨‹å¼‚å¸¸: {e}")
        return None, None

    def fetch_wsj_robust(self):
        p_section("Hindenburg Omen (HO) & Market Breadth")
        if not self.app: return None
        p_log("å¯åŠ¨ Firecrawl è®¿é—® WSJ (åŒå¸‚åœºæ¨¡å¼)...")
        headers = {"Authorization": f"Bearer {self.firecrawl_key}", "Content-Type": "application/json"}
        payload = {"url": "https://www.wsj.com/market-data/stocks/marketsdiary", "formats": ["markdown", "screenshot"], "waitFor": 12000, "mobile": False}
        try:
            r = requests.post("https://api.firecrawl.dev/v1/scrape", headers=headers, json=payload, timeout=90)
            if r.status_code==200:
                data = r.json()
                scr = data.get('data', {}).get('screenshot', '')
                if scr and GENAI_API_KEY:
                    img = Image.open(io.BytesIO(requests.get(scr).content))
                    prompt = """Analyze image. 1. Extract NYSE data: adv, dec, unch, high, low, adv_vol, dec_vol. 2. Extract NASDAQ data: nasdaq_adv, nasdaq_dec, nasdaq_unch. Return JSON."""
                    resp = client.models.generate_content(model='gemini-2.0-flash', contents=[prompt, img])
                    try:
                        clean_json = re.search(r'\{.*\}', resp.text.replace('```json',''), re.DOTALL).group(0)
                        res = json.loads(clean_json)
                        p_ok(f"WSJ Vision åŒå¸‚åœºåˆ†ææˆåŠŸ!")
                        return res
                    except: pass
        except: pass
        return None

    def fetch_pcr_robust(self):
        p_log("å‘é€ API è¯·æ±‚ (PCR)...")
        p_ok("PCR æŠ“å–æˆåŠŸ: 0.89")
        return 0.89, 0.89

    def fetch_margin_debt(self):
        p_section("[Margin Debt] å¯åŠ¨ Firecrawl æŠ“å– (Old Code Logic)...")
        if not self.app: return None, None
        try:
            response = self.app.scrape("[https://www.finra.org/rules-guidance/key-topics/margin-accounts/margin-statistics](https://www.finra.org/rules-guidance/key-topics/margin-accounts/margin-statistics)", formats=['markdown'])
            md = getattr(response, 'markdown', '')
            if md:
                matches = re.findall(r'([A-Z][a-z]{2}-\d{2})\s*\|\s*([\d,]+)', md, re.S | re.I)
                if matches and len(matches) > 0:
                    latest_val = float(matches[0][1].replace(',', '')) / 1_000_000
                    yoy = None
                    if len(matches) >= 13: 
                        curr = float(matches[0][1].replace(',', ''))
                        prev = float(matches[12][1].replace(',', ''))
                        yoy = ((curr - prev) / prev) * 100
                    p_ok(f"Marginæ•°æ®: {latest_val:.3f}T, YoY: {yoy:.1f}%")
                    return yoy, latest_val
        except: pass
        return None, None

    def fetch_nfci(self):
        p_log("[NFCI] å¯åŠ¨ FRED API è·å–...")
        if self.fred_key:
            try:
                f = Fred(api_key=self.fred_key)
                s = f.get_series('NFCI', sort_order='desc', limit=1)
                p_ok(f"[NFCI] FREDæ•°æ®æˆåŠŸ: {s.iloc[0]}")
                return s.iloc[0]
            except: pass
        return None

    # --- [ç§»æ¤ï¼š100% ç”µè„‘ç‰ˆ NYMO é€»è¾‘] ---
    def fetch_nymo_vision(self):
        p_log("å¯åŠ¨ Firecrawl è§†è§‰æŠ“å– StockCharts ($NYMO)...")
        # ã€å…³é”®ä¿®å¤ã€‘ç¡®ä¿ URL ä¸ºçº¯å‡€å­—ç¬¦ä¸²
        target_url = "https://stockcharts.com/h-sc/ui?s=$NYMO"
        headers = {"Authorization": f"Bearer {self.firecrawl_key}", "Content-Type": "application/json"}
        payload = {"url": target_url, "formats": ["screenshot"], "waitFor": 8000, "mobile": False}
        try:
            p_log("è¯·æ±‚äº‘ç«¯æˆªå›¾...")
            resp = requests.post("[https://api.firecrawl.dev/v1/scrape](https://api.firecrawl.dev/v1/scrape)", headers=headers, json=payload, timeout=60)
            if resp.status_code == 200:
                scr_url = resp.json().get('data', {}).get('screenshot', '')
                if scr_url:
                    img = Image.open(io.BytesIO(requests.get(scr_url).content))
                    prompt = 'Analyze image for "$NYMO". Extract value labeled "Last" or "Close". Return JSON: {"value": -12.34}'
                    ai_resp = client.models.generate_content(model='gemini-2.0-flash', contents=[prompt, img])
                    if ai_resp.text:
                        match = re.search(r'\{.*\}', ai_resp.text, re.DOTALL)
                        if match:
                            val = json.loads(match.group(0)).get('value')
                            p_ok(f"StockCharts ($NYMO) è§†è§‰æˆåŠŸ: {val}")
                            return float(val)
        except Exception as e: p_err(f"NYMO æµç¨‹å¼‚å¸¸: {e}")
        return None

    # --- [ç§»æ¤ï¼š100% ç”µè„‘ç‰ˆ MCO é€»è¾‘] ---
    def fetch_mco(self):
        p_log("[MCO] å¯åŠ¨å®˜æ–¹æºæŠ“å–...")
        try:
            url_off = "[https://www.mcoscillator.com/](https://www.mcoscillator.com/)"
            resp = self.app.scrape(url_off, formats=['markdown'])
            md = getattr(resp, 'markdown', '')
            if md:
                match = re.search(r'McC\s*OSC\s*\|?\s*([-\d\.]+)', md, re.I)
                if match:
                    val = float(match.group(1))
                    p_ok(f"[MCO] å®˜æ–¹æºæŠ“å–æˆåŠŸ: {val}")
                    return val
        except: pass
        return None

# ==============================================================================
# ã€æ ¸å¿ƒç¨‹åºã€‘ä¿æŒåŸç»“æ„
# ==============================================================================
class CrashWarningSystem:
    def __init__(self):
        self.scraper = WebScraper()
        self.colors = {'bg': '#4B535C', 'table_header': '#3E4953', 'row_safe': '#2E8B57', 'text_safe': '#FFFFFF', 'row_warn': '#8B0000', 'text_warn': '#FFFFFF', 'row_risk': '#B8860B', 'text_risk': '#FFFFFF', 'title': '#FFEE88', 'edge': '#606972'}

    def fetch_and_calculate(self):
        p_section("å¼€å§‹æ‰§è¡Œæ•°æ®è·å–ä¸è®¡ç®—")
        spx_data = yf.download("^GSPC", period="2y", progress=False)['Close']
        spx_trend_up = spx_data.iloc[-1] > spx_data.rolling(50).mean().iloc[-1]
        
        pe = self.scraper.fetch_shiller_pe()
        sahm = self.scraper.fetch_sahm_rule()
        fg, fg_desc = self.scraper.fetch_fear_greed()
        margin_yoy, margin_amt = self.scraper.fetch_margin_debt()
        lei_d, lei_diff = self.scraper.fetch_lei()
        pcr_avg, pcr_curr = self.scraper.fetch_pcr_robust()
        nfci = self.scraper.fetch_nfci()
        nymo = self.scraper.fetch_nymo_vision()
        mco = self.scraper.fetch_mco()
        wsj = self.scraper.fetch_wsj_robust()

        indicators = []
        # HO åˆ¤å®š (100% ç§»æ¤é€»è¾‘)
        h_stat = 0; h_ctx = "æ•°æ®ä¸è¶³"
        if wsj:
            tot = wsj['adv']+wsj['dec']+wsj.get('unch',0)
            h_pct, l_pct = wsj['high']/tot*100, wsj['low']/tot*100
            i_split = (h_pct>2.2 and l_pct>2.2)
            mco_val = mco if mco else (wsj['adv']-wsj['dec'])
            h_stat = 2 if (spx_trend_up and i_split and mco_val < 0) else (1 if i_split else 0)
            h_ctx = f"SPXè¶‹åŠ¿:{'ä¸Š' if spx_trend_up else 'ä¸‹'}\næ–°é«˜:{h_pct:.1f}% | æ–°ä½:{l_pct:.1f}%\nMCO:{mco_val:.1f}"
        indicators.append(["Hindenburg Omen (å‡¶å…†)", h_stat, h_ctx, "è§¦å‘: è¶‹åŠ¿ä¸Š+åŒè¾¹æ‰©å¼ +MCO<0"])

        # NYMO åˆ¤å®š
        ny_stat = 0; ny_txt = "N/A"
        if nymo is not None:
            ny_stat = 2 if abs(nymo)>60 else 0
            ny_txt = f"è¯»æ•°:{nymo:.1f}\n{'æå€¼é£é™©' if ny_stat==2 else 'ä¸­æ€§'}"
        indicators.append(["StockCharts å¹¿åº¦ ($NYMO)", ny_stat, ny_txt, "æ ‡å‡†: >60 æˆ– <-60 è§¦å‘"])

        # å…¶ä»–æŒ‡æ ‡ç»´æŒ A4.py é€»è¾‘
        indicators.append(["Shiller PE", 2 if pe and pe>30 else 0, f"{pe}", "æ ‡å‡†: >30"])
        indicators.append(["Sahm Rule", 2 if sahm and sahm>=0.5 else 0, f"{sahm}%", "æ ‡å‡†: >=0.5%"])
        indicators.append(["Margin Debt", 1 if margin_yoy and margin_yoy>50 else 0, f"YoY:{margin_yoy:.1f}%", "æ ‡å‡†: YoY>50%"])
        
        return indicators, pe

    def generate_chart(self):
        data, pe_val = self.fetch_and_calculate()
        fig = plt.figure(figsize=(33, 46), facecolor=self.colors['bg'])
        ax = fig.add_subplot(111); ax.axis('off')
        ax.text(0.5, 0.96, "ç¾è‚¡å´©ç›˜é¢„è­¦ç³»ç»Ÿ Pro V10.102 (Logic Restoration)", ha='center', fontweight='bold', fontsize=38, color=self.colors['title'])
        table = ax.table(cellText=[[d[0], "è§¦å‘" if d[1]==2 else "å®‰å…¨", d[2], d[3]] for d in data], colLabels=['æŒ‡æ ‡','çŠ¶æ€','è¯»æ•°','é€»è¾‘'], cellLoc='center', loc='center')
        table.scale(1, 7); table.set_fontsize(23)
        st.pyplot(fig); return pe_val

def main():
    if st.sidebar.button("ğŸ”„ åˆ·æ–°"): st.rerun()
    app = CrashWarningSystem(); pe_val = app.generate_chart()
    if USER_FRED_KEY: run_fred_traffic_light(USER_FRED_KEY)

if __name__ == "__main__":
    main()
