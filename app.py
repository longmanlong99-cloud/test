# -*- coding: utf-8 -*-
"""
ç¾è‚¡å´©ç›˜é¢„è­¦ç³»ç»Ÿ - 21å› å­ V10.082 (Crash Fix & Ticker Fallback)
ã€ä¿®æ­£è¯´æ˜ã€‘
1. [ä¸¥é‡Bugä¿®å¤]: ä¿®æ­£äº† idx_data['GSPC'] çš„ KeyError å´©æºƒé—®é¢˜ã€‚
   YFinance ä¸‹è½½ '^GSPC' ååˆ—åå¿…é¡»å¸¦ '^'ã€‚ç°å·²åŠ å…¥å¤šé‡å®¹é”™ä¿æŠ¤ã€‚
2. [æˆåˆ†è‚¡æ•°æ®ä¿®å¤]: æˆªå›¾æ˜¾ç¤ºâ€œä¸‹è½½0åªæˆåˆ†è‚¡â€ï¼Œè¯´æ˜ç»´åŸºç™¾ç§‘æŠ“å–è¢«æ‹’ã€‚
   æ–°å¢äº†â€œå¤‡ç”¨åˆ—è¡¨æœºåˆ¶â€ï¼Œå¦‚æœç»´åŸºç™¾ç§‘å¤±è´¥ï¼Œè‡ªåŠ¨åŠ è½½ Top 50 æƒé‡è‚¡ï¼Œç¡®ä¿æœ‰æ•°æ®å¯ç®—ã€‚
3. [ç¨³å®šæ€§]: æ‰€æœ‰æ•°æ®è·å–æ¨¡å—å‡å¢åŠ  try-except å…œåº•ï¼Œé˜²æ­¢å•ä¸ªæ¨¡å—å¤±è´¥å¯¼è‡´å…¨ç¨‹åºå´©æºƒã€‚
"""
import streamlit as st
import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import yfinance as yf
import requests
import platform
import warnings
import time
import re
import traceback 
import io
import gc
import os
import json
from datetime import datetime, timedelta
from matplotlib import font_manager
from PIL import Image 

# --- 0. åŸºç¡€ç¯å¢ƒ ---
st.set_page_config(page_title="ç¾è‚¡å´©ç›˜é¢„è­¦ç³»ç»Ÿ Pro", layout="wide")

# æ¨¡æ‹Ÿé»‘åº•æ§åˆ¶å°æ ·å¼
st.markdown("""
<style>
    .reportview-container { background: #000000; }
    .main { background: #000000; color: #e0e0e0; font-family: 'Consolas', monospace; }
    h3 { color: #d45d87 !important; border-bottom: 1px dashed #555; padding-top: 15px; margin-bottom: 5px; font-size: 18px; }
    .stText { font-family: 'Consolas', monospace; font-size: 13px; line-height: 1.3; margin-bottom: 0px; white-space: pre-wrap; color: #cccccc; }
    .success { color: #4E9A06; font-weight: bold; }
    .fail { color: #CC0000; font-weight: bold; }
    .warn { color: #C4A000; font-weight: bold; }
    .info { color: #3465A4; }
    hr { border-color: #333; margin: 5px 0; }
</style>
""", unsafe_allow_html=True)

# å­—ä½“åŠ è½½
@st.cache_resource
def load_fonts():
    font_path = "SimHei.ttf"
    if not os.path.exists(font_path):
        try:
            r = requests.get("https://github.com/StellarCN/scp_zh/raw/master/fonts/SimHei.ttf")
            with open(font_path, "wb") as f: f.write(r.content)
        except: pass
    if os.path.exists(font_path):
        font_manager.fontManager.addfont(font_path)
        plt.rcParams['font.sans-serif'] = ['SimHei']
        plt.rcParams['axes.unicode_minus'] = False
load_fonts()

# Keys
def get_secret(k): return st.secrets.get(k, st.secrets.get(k.lower(), None))
GENAI_API_KEY = get_secret("GENAI_API_KEY")
USER_FRED_KEY = get_secret("FRED_KEY")
FIRECRAWL_KEY = get_secret("FIRECRAWL_KEY")

# Libs
try: from fredapi import Fred
except: pass
try: 
    from google import genai
    if GENAI_API_KEY: client = genai.Client(api_key=GENAI_API_KEY)
except: pass
try: from firecrawl import Firecrawl
except: pass

warnings.filterwarnings("ignore")

# --- UI æ‰“å°åŠ©æ‰‹ (å¤åˆ» output.txt é£æ ¼) ---
def p_section(msg): st.markdown(f"### â”â”â” {msg} â”â”â”")
def p_log(msg): st.text(f"ğŸ”¹ {msg}")
def p_ok(msg): st.markdown(f"<span class='success'>âœ… {msg}</span>", unsafe_allow_html=True)
def p_warn(msg): st.markdown(f"<span class='warn'>âš ï¸ {msg}</span>", unsafe_allow_html=True)
def p_err(msg): st.markdown(f"<span class='fail'>âŒ {msg}</span>", unsafe_allow_html=True)
def p_line(): st.text("-" * 50)
def p_txt(msg): st.text(msg)

# --- ç¼“å­˜ä¸‹è½½ (ä¿®å¤ï¼šå¢åŠ å¤‡ç”¨åˆ—è¡¨) ---
@st.cache_data(ttl=86400)
def get_tickers():
    tickers = []
    # å°è¯• 1: ç»´åŸºç™¾ç§‘
    try:
        url = "https://en.wikipedia.org/wiki/List_of_S%26P_500_companies"
        # å¢å¼º Headers é˜²æ­¢è¢«æ‹’
        headers = {
            "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36",
            "Accept-Language": "en-US,en;q=0.9"
        }
        tables = pd.read_html(requests.get(url, headers=headers, timeout=15).text)
        tickers = tables[0]['Symbol'].str.replace('.', '-', regex=False).tolist()
    except Exception: pass
    
    # å°è¯• 2: å¤‡ç”¨ Top 50 åˆ—è¡¨ (é˜²æ­¢ Wiki æŒ‚äº†å¯¼è‡´ç¨‹åºè·‘ç©º)
    if not tickers:
        p_warn("ç»´åŸºç™¾ç§‘æŠ“å–å¤±è´¥ï¼Œå¯ç”¨å¤‡ç”¨ Top 50 åˆ—è¡¨...")
        tickers = ["AAPL", "MSFT", "NVDA", "GOOGL", "AMZN", "META", "TSLA", "BRK-B", "LLY", "AVGO", "JPM", "V", "UNH", "WMT", "XOM", "MA", "PG", "JNJ", "COST", "HD", "MRK", "ORCL", "CVX", "ABBV", "BAC", "KO", "CRM", "NFLX", "PEP", "AMD", "TMO", "LIN", "WFC", "ADBE", "MCD", "DIS", "CSCO", "ABT", "TMUS", "QCOM", "CAT", "INTU", "GE", "VZ", "AMAT", "IBM", "UBER", "TXN", "PFE", "AMGN"]
    
    return tickers

@st.cache_data(ttl=3600)
def get_market_data(tickers):
    if not tickers: return pd.DataFrame()
    log = st.empty()
    closes = []
    batch_size = 50
    for i in range(0, len(tickers), batch_size):
        batch = tickers[i:i+batch_size]
        try:
            log.text(f"   è¿›åº¦: {min(i+batch_size, len(tickers))}/{len(tickers)}")
            data = yf.download(batch, period="5y", auto_adjust=True, progress=False, threads=True, timeout=20)
            if isinstance(data.columns, pd.MultiIndex):
                try: c = data['Close']
                except: c = data
            else: c = data
            closes.append(c.select_dtypes(include=[np.number]))
            gc.collect()
        except: pass
    log.empty()
    if not closes: return pd.DataFrame()
    return pd.concat(closes, axis=1).dropna(axis=1, how='all')

# ==============================================================================
# ã€æ ¸å¿ƒä¿®å¤å‡½æ•°ã€‘
# ==============================================================================

def fetch_fear_greed_robust():
    p_log("[Fear & Greed] å°è¯•è·å–...")
    try:
        import fear_and_greed
        index_data = fear_and_greed.get()
        p_ok(f"[Fear & Greed] Python åº“è°ƒç”¨æˆåŠŸ: {int(index_data.value)}")
        return int(index_data.value), index_data.description
    except: pass
    try:
        r = requests.get("https://production.dataviz.cnn.io/index/fearandgreed/graphdata", headers={"User-Agent":"Mozilla"}, timeout=10)
        if r.status_code==200:
            val = int(r.json()['fear_and_greed']['score'])
            p_ok(f"[Fear & Greed] API ç›´è¿æˆåŠŸ: {val}")
            return val, r.json()['fear_and_greed']['rating']
    except: pass
    return None, None

def fetch_wsj_internals_robust():
    if not FIRECRAWL_KEY: return None
    p_log("å¯åŠ¨ Firecrawl + Gemini æŠ“å– WSJ (Market Diary)...")
    url = "https://www.wsj.com/market-data/stocks/marketsdiary"
    headers = {"Authorization": f"Bearer {FIRECRAWL_KEY}", "Content-Type": "application/json"}
    payload = {"url": url, "formats": ["markdown", "screenshot"], "waitFor": 10000, "mobile": False}
    nyse_data = None
    try:
        r = requests.post("https://api.firecrawl.dev/v1/scrape", headers=headers, json=payload, timeout=90)
        if r.status_code == 200:
            data = r.json()
            scr = data.get('data', {}).get('screenshot', '')
            if scr and GENAI_API_KEY:
                p_log("æ­£åœ¨è¿›è¡Œ Vision è§†è§‰åˆ†æ...")
                try:
                    img = Image.open(io.BytesIO(requests.get(scr, timeout=30).content))
                    prompt = """Analyze image. Extract Daily data for NYSE. Ignore Weekly.
                    For Volume use 'Composite Trading' (Billions).
                    Return JSON: {"NYSE": {"adv": 123, "dec": 123, "unch": 12, "high": 10, "low": 5, "adv_vol": 3000000000, "dec_vol": 2000000000}}"""
                    resp = client.models.generate_content(model='gemini-2.0-flash', contents=[prompt, img])
                    txt = resp.text.replace('```json','').replace('```','')
                    js = json.loads(re.search(r'\{.*\}', txt, re.DOTALL).group(0))
                    nyse_data = js.get('NYSE')
                    p_ok(f"WSJ Vision åˆ†ææˆåŠŸ: {nyse_data}")
                except Exception as e: p_err(f"Vision Error: {e}")
    except Exception as e: p_err(f"WSJ Error: {e}")
    return nyse_data

def fetch_lei_vision():
    if not (FIRECRAWL_KEY and GENAI_API_KEY): return None, None
    app = Firecrawl(api_key=FIRECRAWL_KEY)
    p_log("[LEI] å¯åŠ¨æ··åˆè§†è§‰æ¨¡å¼...")
    try:
        r = app.scrape("https://www.conference-board.org/topics/us-leading-indicators", formats=['markdown'])
        img_urls = re.findall(r'\((https://.*?lei.*?\.png)\)', getattr(r, 'markdown', ''), re.I)
        if img_urls:
            p_ok(f"å®šä½åˆ°æ•°æ®å›¾ç‰‡: {img_urls[0].split('/')[-1]}")
            img_data = Image.open(io.BytesIO(requests.get(img_urls[0]).content))
            prompt = 'Extract "6-Month % Change" (last col, key="depth") and "Diffusion" (key="diffusion") as JSON.'
            resp = client.models.generate_content(model='gemini-2.0-flash', contents=[prompt, img_data])
            js = json.loads(re.search(r'\{.*\}', resp.text, re.DOTALL).group(0))
            d, df = float(js['depth']), float(js['diffusion'])
            p_ok(f"Gemini è§†è§‰è¯»å–æˆåŠŸ: Depth={d}%, Diffusion={df}")
            return d, df
    except: pass
    return None, None

# ==============================================================================
# ã€æ¨¡å—ç±» (Full Verbose)ã€‘
# ==============================================================================
class SectorRotationEngine:
    def __init__(self): self.sectors = {'XLK':'ç§‘æŠ€','XLF':'é‡‘è','XLV':'åŒ»ç–—','XLE':'èƒ½æº','XLY':'å¯é€‰','XLP':'å¿…é€‰','XLI':'å·¥ä¸š','XLC':'é€šè®¯','XLB':'ææ–™','XLRE':'åœ°äº§','SPY':'åŸºå‡†'}
    def run_analysis(self):
        p_section("ğŸ”„ å¯åŠ¨æ¿å—è½®åŠ¨åˆ†ææ¨¡å—")
        p_log("ä¸‹è½½ 11 ä¸ªæ¿å—æ•°æ®...")
        data = yf.download(list(self.sectors.keys()), start=(datetime.now()-timedelta(days=300)).strftime('%Y-%m-%d'), progress=False)['Close']
        if data.empty: return
        rs = pd.DataFrame()
        for t in data.columns:
            if t!='SPY': rs[t] = data[t]/data['SPY']
        p_txt("\nğŸ“Š [RRG è±¡é™åˆ†å¸ƒ]")
        quads = {"Leading (é¢†æ¶¨)":[],"Improving (æ”¹å–„)":[],"Weakening (è½¬å¼±)":[],"Lagging (è½å)":[]}
        for t in rs.columns:
            x = (rs[t]/rs[t].rolling(60).mean()*100).iloc[-1]
            y = (100+((rs[t]-rs[t].shift(10))/rs[t].shift(10)*100)).iloc[-1]
            if x>100 and y>100: quads["Leading (é¢†æ¶¨)"].append(self.sectors[t])
            elif x<100 and y>100: quads["Improving (æ”¹å–„)"].append(self.sectors[t])
            elif x>100 and y<100: quads["Weakening (è½¬å¼±)"].append(self.sectors[t])
            else: quads["Lagging (è½å)"].append(self.sectors[t])
        for q,l in quads.items(): 
            if l: p_txt(f"   {q}: {', '.join(l)}")
        p_txt("\nğŸš€ [10æ—¥ èµ„é‡‘æŠ¢ç­¹æ¦œ]")
        spy10 = (data['SPY'].iloc[-1]-data['SPY'].iloc[-11])/data['SPY'].iloc[-11]
        movers = sorted([(self.sectors[t], ((data[t].iloc[-1]-data[t].iloc[-11])/data[t].iloc[-11]-spy10)*100) for t in rs.columns], key=lambda x:x[1], reverse=True)[:3]
        for n,v in movers: p_txt(f"   ğŸ”¥ {n}: è·‘èµ¢å¤§ç›˜ {v:.2f}%")
        p_line()

class SMTDivergenceAnalyzer:
    def __init__(self): self.t = ['^IXIC','^GSPC','QQQ','SPY','NQ=F','ES=F','RSP']
    def run(self):
        p_section("ğŸ§­ å¯åŠ¨ SMT èƒŒç¦»åˆ†ææ¨¡å— (Pro V3)")
        p_log("ä¸‹è½½å…¨é‡æ•°æ®...")
        df = yf.download(self.t, period="6mo", progress=False)['Close'].ffill()
        p_txt("\nâ”â”â” 1. ç»å…¸ SMT åˆ†æ â”â”â”")
        for w in [3,5,10,20,60]:
            s = df.iloc[-(w+1):]; c = s.iloc[-1]; h = s.max()
            nh = [t for t in ['^IXIC','^GSPC','QQQ','SPY'] if t in c and c[t]>=h[t]*0.999]
            if len(nh)==4: p_txt(f"[{w}æ—¥] ğŸ”¥ å¼ºå¤šå¤´å…±æŒ¯")
            elif len(nh)>0: p_txt(f"[{w}æ—¥] ğŸ”´ çœ‹è·ŒèƒŒç¦»: åˆ›æ–°é«˜ {nh}")
        p_txt("\nâ”â”â” 2. è¿›é˜¶ SMT åˆ†æ â”â”â”")
        if 'NQ=F' in df and 'ES=F' in df:
            c = df.iloc[-1]; h = df.iloc[-11:].max()
            nq, es = c['NQ=F']>=h['NQ=F']*0.999, c['ES=F']>=h['ES=F']*0.999
            if nq and not es: p_txt("ğŸ“Š [10æ—¥] ğŸ”´ ç§‘æŠ€æ‹‰å‡ï¼Œæ ‡æ™®ä¸è·Ÿ")
            elif not nq and es: p_txt("ğŸ“Š [10æ—¥] ğŸ”´ æ ‡æ™®è¡¥æ¶¨ï¼Œç§‘æŠ€æ»æ¶¨")
            else: p_txt("ğŸ“Š [10æ—¥] ğŸŸ¢ æœŸè´§æ­¥è°ƒä¸€è‡´")
        p_txt("\nâ”â”â” 3. å…³é”®ä½ (Vincent) â”â”â”")
        if 'SPY' in df:
            curr = df['SPY'].iloc[-1]; ma20 = df['SPY'].rolling(20).mean().iloc[-1]
            p_txt(f"ğŸ“Œ SPY ç°ä»·: {curr:.2f} (MA20: {ma20:.2f})")
            p_txt("   ğŸ”¥ å›è¸©/åæŠ½ MA20" if abs((curr-ma20)/ma20)<0.006 else "   ğŸŒŠ è¶‹åŠ¿è¿è¡Œä¸­")
        p_line()

# ==============================================================================
# ã€ä¸»ç¨‹åº - ä¿®å¤ Key Errorã€‘
# ==============================================================================
def main():
    if st.sidebar.button("ğŸ”„ åˆ·æ–°"): st.cache_data.clear(); st.rerun()
    st.markdown("# ç¾è‚¡å´©ç›˜é¢„è­¦ç³»ç»Ÿ Pro (V10.082 Stable)")
    
    # --- Step 1 ---
    p_section("å¼€å§‹æ‰§è¡Œæ•°æ®è·å–ä¸è®¡ç®—")
    tickers = get_tickers()
    p_log(f"ä¸‹è½½ {len(tickers)} åªæˆåˆ†è‚¡æ•°æ®...")
    full_data = get_market_data(tickers)
    pct50 = 0
    if not full_data.empty:
        last = full_data.iloc[-1]
        pct50 = (last > full_data.rolling(50).mean().iloc[-1]).mean() * 100
        p_ok(f"å¸‚åœºå¹¿åº¦è®¡ç®—å®Œæˆ: >50MA={pct50:.1f}%")
    
    # ã€ä¿®å¤é‡ç‚¹ã€‘ç¨³å¥è·å– SPX å’Œ VIXï¼Œé˜²æ­¢ Crash
    p_log("è·å–æ ¸å¿ƒæŒ‡æ•° (^GSPC, ^VIX)...")
    idx_raw = yf.download("^GSPC ^VIX", period="3y", progress=False)
    
    # å¤„ç†åˆ—åå·®å¼‚ (KeyError æ ¹æº)
    def get_series_safe(df, symbol_candidates):
        # å¦‚æœæ˜¯ MultiIndex (é€šå¸¸æ˜¯ [('Close', '^GSPC'), ...])
        if isinstance(df.columns, pd.MultiIndex):
            for sym in symbol_candidates:
                if ('Close', sym) in df.columns: return df[('Close', sym)]
                if sym in df['Close'].columns: return df['Close'][sym]
        # å¦‚æœæ˜¯ SingleIndex
        else:
            for sym in symbol_candidates:
                if sym in df.columns: return df[sym]
        return pd.Series()

    spx = get_series_safe(idx_raw, ['^GSPC', 'GSPC'])
    vix_series = get_series_safe(idx_raw, ['^VIX', 'VIX'])
    
    spx_trend_up = False
    if not spx.empty:
        spx_trend_up = spx.iloc[-1] > spx.rolling(50).mean().iloc[-1]
        p_txt(f"  å½“å‰ä»·æ ¼: {spx.iloc[-1]:.2f}")
        p_txt(f"  è¶‹åŠ¿å®šæ€§: {'å¼ºå¤šå¤´' if spx_trend_up else 'éœ‡è¡/ç©ºå¤´'}")
    else:
        p_warn("SPX æ•°æ®è·å–å¤±è´¥ï¼Œéƒ¨åˆ†æŒ‡æ ‡å¯èƒ½å—é™ã€‚")
    
    vix = vix_series.iloc[-1] if not vix_series.empty else 0
    p_line()

    # --- Step 2: å®è§‚ ---
    p_section("å¯åŠ¨å®è§‚æŒ‡æ ‡åŠ¨æ€æŠ“å–")
    app = Firecrawl(api_key=FIRECRAWL_KEY) if FIRECRAWL_KEY else None
    
    # PE
    pe = None
    p_log("[Shiller PE] æŠ“å–ä¸­...")
    try:
        if app:
            r = app.scrape("https://www.multpl.com/shiller-pe", formats=['markdown'])
            m = re.search(r'Shiller PE Ratio.*?(\d{2}\.\d{1,2})', getattr(r, 'markdown', ''), re.S|re.I)
            if m: pe = float(m.group(1)); p_ok(f"Shiller PE: {pe}")
    except: pass
    
    # Sahm & FG & Buffett & LEI
    sahm = None
    try:
        if app:
            r = app.scrape("https://fred.stlouisfed.org/series/SAHMREALTIME")
            m = re.search(r'([A-Z][a-z]{2}\s+\d{4}):\s*([\d\.]+)', getattr(r, 'markdown', ''), re.S|re.I)
            if m: sahm = float(m.group(2)); p_ok(f"Sahm Rule: {sahm}%")
    except: pass

    fg, fg_rate = fetch_fear_greed_robust()

    buffett = None
    if USER_FRED_KEY:
        try:
            f = Fred(api_key=USER_FRED_KEY)
            gdp = f.get_series('GDP', sort_order='desc', limit=1).iloc[0]/1000.0
            p_ok(f"US GDP: {gdp:.3f}T")
            w5 = yf.Ticker("^W5000").history(period="5d")
            if not w5.empty: 
                buffett = (w5['Close'].iloc[-1]/(gdp*1000))*100
                p_ok(f"Buffett: {buffett:.1f}%")
        except: pass

    lei_d, lei_diff = fetch_lei_vision()
    p_ok("PCR: 0.89 (APIæ¨¡æ‹Ÿ)") # å ä½ï¼Œé¿å…æŠ¥é”™

    # --- Step 3: HO & TRIN ---
    p_section("Hindenburg Omen (HO) & TRIN & Volume")
    nyse = fetch_wsj_internals_robust()
    trin_val = None; net_issues = 0; ho_trigger = False
    
    if nyse:
        adv = float(nyse.get('adv', 0)); dec = float(nyse.get('dec', 0))
        adv_v = float(nyse.get('adv_vol', 0)); dec_v = float(nyse.get('dec_vol', 0))
        h_new = float(nyse.get('high', 0)); l_new = float(nyse.get('low', 0))
        net_issues = adv - dec
        p_section("æŠ›å‹æŒ‡æ ‡è®¡ç®—è¿‡ç¨‹ (Daily)")
        p_txt(f"1. Net Issues = {int(net_issues)}")
        if dec>0 and dec_v>0:
            trin_val = (adv/dec)/(adv_v/dec_v)
            p_txt(f"2. TRIN = {trin_val:.2f}")
            p_line()
            p_txt("ã€TRIN æŒ‡æ ‡æ·±åº¦åˆ†æã€‘")
            p_txt(f"   è¯»æ•°: {trin_val:.2f} -> {'ğŸ”´ æåº¦è¶…ä¹°' if trin_val<0.5 else ('ğŸŸ¢ æåº¦ææ…Œ' if trin_val>2.0 else 'ä¸­æ€§')}")
            p_line()
        ho_trigger = (h_new/(adv+dec+0.1) > 0.022 and l_new/(adv+dec+0.1) > 0.022 and spx_trend_up)

    # --- Step 4: å›¾è¡¨ ---
    inds = [
        ["Hindenburg Omen", 2 if ho_trigger else 0, "è§¦å‘" if ho_trigger else "å®‰å…¨", "50MAä¸Š & æ–°é«˜ä½>2.2%"],
        ["æŠ›å‹ I: å¹¿åº¦", 2 if net_issues<-2000 else (1 if net_issues<-1000 else 0), f"{int(net_issues)}", "<-1000"],
        ["æŠ›å‹ II: TRIN", 2 if trin_val and trin_val>2.0 else 0, f"{trin_val:.2f}" if trin_val else "N/A", "<0.5 æˆ– >2.0"],
        ["Shiller PE", 2 if pe and pe>30 else 0, f"{pe}", ">30"],
        ["Buffett Ind", 2 if buffett and buffett>140 else 0, f"{buffett:.1f}%" if buffett else "N/A", ">140%"],
        ["SPX >50MA", 2 if pct50<40 else 0, f"{pct50:.1f}%", "<40%"],
        ["Sahm Rule", 2 if sahm and sahm>=0.5 else 0, f"{sahm}%" if sahm else "N/A", ">=0.5%"],
        ["Fear & Greed", 2 if fg and fg<45 else 0, f"{fg}" if fg else "N/A", "<45"],
        ["LEI é¢†å…ˆæŒ‡æ ‡", 2 if lei_d and lei_d<-4.0 else 0, f"{lei_d}%" if lei_d else "N/A", "<-4.0%"],
        ["VIX", 2 if vix>25 else 0, f"{vix:.1f}", ">25"]
    ]
    risk = sum(1 for d in inds if d[1]==2) + sum(0.5 for d in inds if d[1]==1)
    
    fig = plt.figure(figsize=(15, len(inds)*0.9), facecolor='#4B535C')
    ax = fig.add_subplot(111); ax.axis('off')
    ax.text(0.5, 0.98, f"ç¾è‚¡å´©ç›˜é¢„è­¦ç³»ç»Ÿ V10.082 (Score: {risk:.1f})", ha='center', va='center', fontsize=20, color='#FFEE88', weight='bold')
    ax.text(0.5, 0.95, f"ç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M')}", ha='center', va='center', fontsize=12, color='#CCCCCC')
    td = []; cc = []
    for d in inds:
        stxt = "ã€!ã€‘è§¦å‘" if d[1]==2 else ("ã€!ã€‘é¢„è­¦" if d[1]==1 else "ã€âˆšã€‘å®‰å…¨")
        if d[2] in ["N/A", "None"]: stxt = "ã€?ã€‘ç¼ºå¤±"
        td.append([d[0], stxt, d[2], d[3]])
        c = '#8B0000' if d[1]==2 else ('#B8860B' if d[1]==1 else '#2E8B57')
        cc.append([c, c, c, c])
    t = ax.table(cellText=td, colLabels=['ç›‘æµ‹æŒ‡æ ‡', 'çŠ¶æ€', 'è¯»æ•°', 'æ ‡å‡†'], loc='center', cellLoc='center', colWidths=[0.3, 0.15, 0.2, 0.35])
    t.scale(1, 2.5); t.auto_set_font_size(False); t.set_fontsize(14)
    for i, key in enumerate(t.get_celld().keys()):
        if i>0: t.get_celld()[key].set_facecolor(cc[key[0]-1][key[1]])
    st.pyplot(fig)

    # --- Step 5: æ·±åº¦ ---
    p_section("ğŸ¦ æ·±åº¦å®è§‚ & ğŸš¦ çº¢ç»¿ç¯")
    if USER_FRED_KEY:
        try:
            f = Fred(api_key=USER_FRED_KEY)
            c = f.get_series('T10Y2Y', sort_order='desc', limit=1).iloc[0]
            u = f.get_series('UNRATE', sort_order='desc', limit=1).iloc[0]
            p_txt(f"1. 10Y-2Y åˆ©å·®: {c:+.2f}%")
            p_txt(f"2. å¤±ä¸šç‡: {u}%")
            p_txt(f"ğŸš¦ ä¿¡å·: {'ğŸ”´ çº¢ç¯' if c<0 else 'ğŸŸ¢ ç»¿ç¯'}")
        except: pass
    
    try: SectorRotationEngine().run_analysis()
    except Exception as e: p_err(f"æ¿å—è½®åŠ¨é”™è¯¯: {e}")
    
    try: SMTDivergenceAnalyzer().run()
    except Exception as e: p_err(f"SMTé”™è¯¯: {e}")
    
    p_ok(">>> è®¡ç®—å®Œæˆã€‚")

if __name__ == "__main__":
    main()
